# Placeholder for Streamlit UI code 

import streamlit as st
import torch
import os
import time
import pandas as pd
import math
import traceback
from torchvision import transforms # ç¡®ä¿å¯¼å…¥ transforms
from datetime import datetime, timedelta 
# --- æ–°å¢ï¼šå¯¼å…¥ json --- 
import json 

# --- GPU ç›‘æ§ä¾èµ– ---
nvml_available = False
pynvml = None
try:
    import pynvml
    pynvml.nvmlInit()
    nvml_available = True
except ImportError:
    # st.sidebar.info("æç¤ºï¼šæœªæ‰¾åˆ° pynvml åº“ï¼Œæ— æ³•è¿›è¡Œ GPU ç›‘æ§ã€‚å¯å°è¯• `pip install nvidia-ml-py` å®‰è£…ã€‚")
    pass # ä¸åœ¨å¯¼å…¥æ—¶æ˜¾ç¤ºï¼Œé¿å…å¹²æ‰°
except pynvml.NVMLError as e:
    # st.sidebar.warning(f"NVML åˆå§‹åŒ–å¤±è´¥: {e}. æ— æ³•è¿›è¡Œ GPU ç›‘æ§ã€‚")
    pass # ä¸åœ¨å¯¼å…¥æ—¶æ˜¾ç¤º
# --------------------->

# å°è¯•å¯¼å…¥æˆ‘ä»¬è‡ªå·±å†™çš„æ¨¡å—
# æ·»åŠ è·¯å¾„åˆ° sys.path å¯èƒ½æ›´å¥å£®ï¼Œä½†è¿™é‡Œå…ˆç”¨ try-except
try:
    from dataset import DeepFashionDataset, ANNOTATION_DIR_NAME, IMAGE_DIR_NAME
    from model import ClothesModel
    from trainer import Trainer
except ImportError as e:
    st.error(f"é”™è¯¯ï¼šæ— æ³•å¯¼å…¥å¿…è¦çš„æ¨¡å—æˆ–å¸¸é‡ã€‚è¯·ç¡®ä¿ dataset.py, model.py, trainer.py ä¸ main_ui.py åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚é”™è¯¯: {e}")
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œï¼Œé¿å…åç»­é”™è¯¯
    st.stop()

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="æœè£…è¯†åˆ«è®­ç»ƒåœº", layout="wide")
st.title("ğŸ‘•ğŸ‘— æœè£…ç±»åˆ«ä¸å±æ€§è¯†åˆ« - AI è®­ç»ƒåœº")
st.markdown("--- ")

# --- Session State åˆå§‹åŒ– ---
# ä½¿ç”¨ st.session_state æ¥å­˜å‚¨è·¨è¿è¡Œçš„çŠ¶æ€
if 'stop_requested' not in st.session_state:
    st.session_state.stop_requested = False
if 'log_messages' not in st.session_state:
    st.session_state.log_messages = []
if 'history_df_list' not in st.session_state:
    st.session_state.history_df_list = []
if 'selected_strategy' not in st.session_state:
    # é»˜è®¤é€‰æ‹©å‡è¡¡ç­–ç•¥ï¼Œæˆ–è€…è®¾ä¸º None è¡¨ç¤ºæ‰‹åŠ¨
    st.session_state.selected_strategy = "å‡è¡¡æ¨è (Balanced)" 
# --- æ–°å¢ï¼šGPU æŒ‡æ ‡å†å²è®°å½• --- 
if 'gpu_metrics_history' not in st.session_state:
    st.session_state.gpu_metrics_history = []
if 'gpu_poll_step' not in st.session_state:
    st.session_state.gpu_poll_step = 0
# --- æ–°å¢ï¼šæ—¶é—´ç›¸å…³çŠ¶æ€ --- 
if 'training_start_time' not in st.session_state:
    st.session_state.training_start_time = None
if 'epoch_durations' not in st.session_state:
    st.session_state.epoch_durations = []
# ------------------------->

# --- æ–°å¢ï¼šç»“æœæ–‡ä»¶å¸¸é‡ --- 
RESULTS_FILE = "training_results.json"
# ------------------------>

# --- å‡½æ•°å®šä¹‰æå‰ ---

# æ—¥å¿—è¿½åŠ å‡½æ•°
def append_log(message):
    """å°†å¸¦æ—¶é—´æˆ³çš„æ¶ˆæ¯è¿½åŠ åˆ° session_state çš„æ—¥å¿—åˆ—è¡¨ä¸­"""
    st.session_state.log_messages.append(f"[{time.strftime('%H:%M:%S')}] {message}")

# GPU ä¿¡æ¯æ›´æ–°å‡½æ•°
def update_gpu_info(gpu_index, placeholder, chart_placeholders):
    """æ›´æ–°æŒ‡å®šçš„ placeholder åŒºåŸŸçš„ GPU ç›‘æ§ä¿¡æ¯å’Œå›¾è¡¨"""
    gpu_util_chart_placeholder, gpu_mem_chart_placeholder = chart_placeholders
    if nvml_available and pynvml and gpu_index is not None:
        try:
            handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_index)
            util = pynvml.nvmlDeviceGetUtilizationRates(handle)
            mem = pynvml.nvmlDeviceGetMemoryInfo(handle)
            temp = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)
            power_usage = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0 # ç“¦ç‰¹
            power_limit = pynvml.nvmlDeviceGetEnforcedPowerLimit(handle) / 1000.0 # ç“¦ç‰¹

            # ä½¿ç”¨å…¨å±€å˜é‡ gpu_names è·å–åç§°
            gpu_name = gpu_names.get(gpu_index, f"GPU {gpu_index}") 
            gpu_info_str = (
                f"**{gpu_name}:**\n"
                f"- **æ¸©åº¦:** {temp}Â°C\n"
                f"- **ä½¿ç”¨ç‡:** {util.gpu}%\n"
                f"- **æ˜¾å­˜:** {mem.used / 1024**3:.2f} GB / {mem.total / 1024**3:.2f} GB ({mem.used * 100 / mem.total:.1f}%)\n"
                f"- **åŠŸè€—:** {power_usage:.1f} W / {power_limit:.1f} W"
            )
            placeholder.markdown(gpu_info_str) # æ›´æ–°ä¼ å…¥çš„ placeholder

            # --- æ–°å¢ï¼šè®°å½•å’Œç»˜åˆ¶ GPU æŒ‡æ ‡å†å² --- 
            current_step = st.session_state.gpu_poll_step
            memory_util_percent = mem.used * 100 / mem.total if mem.total > 0 else 0
            st.session_state.gpu_metrics_history.append({
                'step': current_step,
                'GPU Utilization (%)': util.gpu,
                'Memory Utilization (%)': memory_util_percent
            })
            st.session_state.gpu_poll_step += 1
            
            # åˆ›å»º DataFrame å¹¶ç»˜å›¾ (åªä¿ç•™æœ€è¿‘ N ä¸ªç‚¹é¿å…è¿‡é•¿ï¼Ÿæš‚æ—¶å…¨ç”»)
            gpu_history_df = pd.DataFrame(st.session_state.gpu_metrics_history)
            if len(gpu_history_df) > 1: # éœ€è¦è‡³å°‘ä¸¤ä¸ªç‚¹æ‰èƒ½ç”»çº¿
                try:
                    gpu_util_chart_placeholder.line_chart(gpu_history_df.set_index('step')['GPU Utilization (%)'])
                    gpu_mem_chart_placeholder.line_chart(gpu_history_df.set_index('step')['Memory Utilization (%)'])
                except Exception as chart_e:
                    # é˜²æ­¢ç»˜å›¾å¤±è´¥å¯¼è‡´æ•´ä¸ªç›‘æ§ä¸­æ–­
                    if 'chart_error_logged' not in st.session_state or not st.session_state.chart_error_logged:
                         st.sidebar.warning(f"ç»˜åˆ¶ GPU å›¾è¡¨æ—¶å‡ºé”™: {chart_e}")
                         st.session_state.chart_error_logged = True
            # --- æ–°å¢ç»“æŸ ---

        except pynvml.NVMLError as e:
            if 'gpu_error_logged' not in st.session_state or not st.session_state.gpu_error_logged:
                placeholder.warning(f"è·å– GPU {gpu_index} ä¿¡æ¯å¤±è´¥: {e}")
                st.session_state.gpu_error_logged = True
        except Exception as e:
             if 'gpu_error_logged' not in st.session_state or not st.session_state.gpu_error_logged:
                placeholder.error(f"æ›´æ–° GPU ä¿¡æ¯æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
                st.session_state.gpu_error_logged = True

# --- æ–°å¢ï¼šæ—¶é—´æ ¼å¼åŒ–å‡½æ•° ---
def format_time_delta(seconds):
    """å°†ç§’æ•°æ ¼å¼åŒ–ä¸º HH:MM:SS"""
    if seconds is None or not math.isfinite(seconds):
        return "N/A"
    delta = timedelta(seconds=int(seconds))
    return str(delta)

# --- æ–°å¢ï¼šè¯Šæ–­æŠ¥å‘Šç”Ÿæˆå‡½æ•° ---
def generate_diagnostic_report(history_df, best_val_loss, total_epochs):
    """æ ¹æ®è®­ç»ƒå†å²ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š"""
    report = []
    report.append("### ğŸ©º è®­ç»ƒè¯Šæ–­æŠ¥å‘Š")

    if history_df is None or history_df.empty:
        report.append("- âŒ æ— æ³•ç”ŸæˆæŠ¥å‘Šï¼šç¼ºå°‘è®­ç»ƒå†å²æ•°æ®ã€‚")
        return "\n".join(report)

    final_epoch_data = history_df.iloc[-1]
    best_epoch_data = history_df.loc[history_df['Validation Loss'].idxmin()] if 'Validation Loss' in history_df.columns and history_df['Validation Loss'].notna().any() else None

    # 1. æ•´ä½“è¡¨ç°
    report.append(f"- **è®­ç»ƒè½®æ•°:** {len(history_df)} / {total_epochs}")
    if best_epoch_data is not None:
        report.append(f"- **æœ€ä½³éªŒè¯æŸå¤±:** {best_epoch_data['Validation Loss']:.4f} (å‡ºç°åœ¨ Epoch {int(best_epoch_data['epoch'])})")
    else:
        report.append("- **æœ€ä½³éªŒè¯æŸå¤±:** æœªè®°å½•æˆ–æ— æ•ˆã€‚")
    report.append(f"- **æœ€ç»ˆéªŒè¯æŸå¤±:** {final_epoch_data['Validation Loss']:.4f}")
    report.append(f"- **æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡:** {final_epoch_data['Validation Accuracy (%)']:.2f}%")

    # 2. æ”¶æ•›æ€§åˆ†æ
    if len(history_df) >= 5:
        last_5_val_loss = history_df['Validation Loss'].tail(5)
        if last_5_val_loss.is_monotonic_decreasing:
            report.append("- **æ”¶æ•›æ€§:** âœ… éªŒè¯æŸå¤±åœ¨æœ€å5è½®æŒç»­ä¸‹é™ï¼Œå¯èƒ½ä»æœ‰æå‡ç©ºé—´ã€‚")
        elif last_5_val_loss.iloc[-1] < last_5_val_loss.iloc[0]:
            report.append("- **æ”¶æ•›æ€§:** âš ï¸ éªŒè¯æŸå¤±åœ¨æœ€å5è½®æœ‰æ‰€æ³¢åŠ¨ï¼Œä½†æ•´ä½“ä»åœ¨ä¸‹é™ã€‚")
        else:
             report.append("- **æ”¶æ•›æ€§:** âŒ éªŒè¯æŸå¤±åœ¨æœ€å5è½®æœªèƒ½æŒç»­ä¸‹é™ï¼Œå¯èƒ½å·²æ”¶æ•›æˆ–é‡åˆ°ç“¶é¢ˆã€‚")
    else:
        report.append("- **æ”¶æ•›æ€§:** âš ï¸ è®­ç»ƒè½®æ•°è¾ƒå°‘ï¼Œéš¾ä»¥åˆ¤æ–­æ”¶æ•›è¶‹åŠ¿ã€‚")

    # 3. è¿‡æ‹Ÿåˆé£é™©
    train_loss_final = final_epoch_data.get('Train Loss', float('nan'))
    val_loss_final = final_epoch_data.get('Validation Loss', float('nan'))
    train_acc_final = final_epoch_data.get('Train Accuracy (%)', float('nan'))
    val_acc_final = final_epoch_data.get('Validation Accuracy (%)', float('nan'))

    loss_diff = abs(train_loss_final - val_loss_final) if math.isfinite(train_loss_final) and math.isfinite(val_loss_final) else float('inf')
    acc_diff = abs(train_acc_final - val_acc_final) if math.isfinite(train_acc_final) and math.isfinite(val_acc_final) else float('inf')

    # è®¾å®šä¸€äº›ç®€å•çš„é˜ˆå€¼ (å¯ä»¥æ ¹æ®ç»éªŒè°ƒæ•´)
    overfitting_risk = "ä½"
    if loss_diff > 0.5 or acc_diff > 15:
        overfitting_risk = "é«˜"
    elif loss_diff > 0.2 or acc_diff > 8:
        overfitting_risk = "ä¸­"

    report.append(f"- **è¿‡æ‹Ÿåˆé£é™©:** {overfitting_risk} (åŸºäºæœ€ç»ˆæŸå¤±å·®å¼‚ {loss_diff:.2f} å’Œå‡†ç¡®ç‡å·®å¼‚ {acc_diff:.1f}%) ")
    if overfitting_risk != "ä½":
        report.append("  - _å»ºè®®: å¯å°è¯•å¢åŠ æ­£åˆ™åŒ–ã€æ•°æ®å¢å¼ºæˆ–æå‰åœæ­¢ã€‚_")

    return "\n".join(report)

# --- æ–°å¢ï¼šåŠŸèƒ½æ¨¡æ‹Ÿæµ‹è¯•å‡½æ•° ---
def run_functional_test(model_save_dir, model_name, model_config, device):
    """å°è¯•åŠ è½½æœ€ä½³æ¨¡å‹å¹¶è¿›è¡Œä¸€æ¬¡æ¨¡æ‹Ÿæ¨ç†"""
    report = ["### âš™ï¸ åŠŸèƒ½æ¨¡æ‹Ÿæµ‹è¯•"] 
    best_model_file = None
    try:
        # æŸ¥æ‰¾æœ€ä½³æ¨¡å‹æ–‡ä»¶
        possible_files = [f for f in os.listdir(model_save_dir) if f.startswith(f"best_model_{model_name}") and f.endswith(".pth")]
        if not possible_files:
            report.append("- âŒ æœªæ‰¾åˆ°ä¿å­˜çš„æœ€ä½³æ¨¡å‹æ–‡ä»¶ã€‚")
            return "\n".join(report), False
        # å¦‚æœæœ‰å¤šä¸ªï¼Œç†è®ºä¸Šä¸è¯¥å‘ç”Ÿï¼Œä½†å¯ä»¥å–æœ€æ–°çš„ï¼ˆæŒ‰æ–‡ä»¶åä¸­çš„epochï¼‰
        possible_files.sort(key=lambda x: int(x.split('_epoch')[-1].split('.')[0]), reverse=True)
        best_model_file = os.path.join(model_save_dir, possible_files[0])
        report.append(f"- æ‰¾åˆ°æœ€ä½³æ¨¡å‹æ–‡ä»¶: `{best_model_file}`")

        # åŠ è½½æ¨¡å‹
        report.append("- å°è¯•åŠ è½½æ¨¡å‹...")
        # éœ€è¦ç¡®ä¿ ClothesModel åœ¨å½“å‰ä½œç”¨åŸŸå¯è§
        from model import ClothesModel # æˆ–è€…ç¡®ä¿å®ƒå·²åœ¨é¡¶éƒ¨å¯¼å…¥
        model = ClothesModel(num_categories=model_config['num_categories'], backbone=model_config['backbone'])
        model.load_state_dict(torch.load(best_model_file, map_location=device))
        model.to(device)
        model.eval()
        report.append("- âœ… æ¨¡å‹åŠ è½½æˆåŠŸã€‚")

        # æ¨¡æ‹Ÿæ¨ç†
        report.append("- å°è¯•æ¨¡æ‹Ÿæ¨ç†...")
        # åˆ›å»ºè™šæ‹Ÿè¾“å…¥ (batch_size=1, channels=3, height=224, width=224)
        dummy_input = torch.randn(1, 3, 224, 224).to(device)
        with torch.no_grad():
            cat_logits, attr_logits = model(dummy_input)
        
        # æ£€æŸ¥è¾“å‡º
        report.append(f"- æ¨¡å‹è¾“å‡º (ç±»åˆ« Logits): {cat_logits.shape}")
        report.append(f"- æ¨¡å‹è¾“å‡º (å±æ€§ Logits): {attr_logits.shape}")
        if cat_logits.shape[0] == 1 and cat_logits.shape[1] == model_config['num_categories'] and \
           attr_logits.shape[0] == 1 and attr_logits.shape[1] == 26: # æ£€æŸ¥å±æ€§ç»´åº¦æ˜¯26
             report.append("- âœ… æ¨¡æ‹Ÿæ¨ç†æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶ç¬¦åˆé¢„æœŸã€‚")
             return "\n".join(report), True
        else:
             report.append("- âŒ æ¨¡æ‹Ÿæ¨ç†å®Œæˆï¼Œä½†è¾“å‡ºå½¢çŠ¶ä¸ç¬¦åˆé¢„æœŸï¼")
             return "\n".join(report), False

    except Exception as e:
        report.append(f"- âŒ åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        append_log(f"åŠŸèƒ½æµ‹è¯•å¤±è´¥: {traceback.format_exc()}") # è®°å½•è¯¦ç»†é”™è¯¯åˆ°æ—¥å¿—
        return "\n".join(report), False

# --- æ–°å¢ï¼šç»“æœåŠ è½½/ä¿å­˜å‡½æ•° ---
def load_results():
    """åŠ è½½å†å²è®­ç»ƒç»“æœ"""
    try:
        with open(RESULTS_FILE, 'r', encoding='utf-8') as f:
            results = json.load(f)
        # ç¡®ä¿è¿”å›çš„æ˜¯åˆ—è¡¨
        return results if isinstance(results, list) else []
    except FileNotFoundError:
        return []
    except json.JSONDecodeError:
        # æ–‡ä»¶æŸåæˆ–ä¸ºç©ºï¼Œè¿”å›ç©ºåˆ—è¡¨
        return []

def save_results(results):
    """ä¿å­˜è®­ç»ƒç»“æœåˆ—è¡¨åˆ° JSON æ–‡ä»¶"""
    try:
        with open(RESULTS_FILE, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=4, ensure_ascii=False)
    except IOError as e:
        st.error(f"æ— æ³•ä¿å­˜è®­ç»ƒç»“æœåˆ° {RESULTS_FILE}: {e}")
# ------------------------------>

# --- ç­–ç•¥å®šä¹‰ ---
STRATEGIES = {
    "å¿«é€Ÿä½“éªŒ (Fast Trial)": {
        "epochs": 5,
        "batch_size": 64,
        "learning_rate": 5e-4,
        "backbone": 'resnet18',
        "attribute_loss_weight": 1.0
    },
    "å‡è¡¡æ¨è (Balanced)": {
        "epochs": 15,
        "batch_size": 32,
        "learning_rate": 1e-4,
        "backbone": 'efficientnet_b3',
        "attribute_loss_weight": 1.0
    },
    "æœ€é«˜ç²¾åº¦ (High Accuracy)": {
        "epochs": 30,
        "batch_size": 32, # ä¿æŒ 32ï¼Œé¿å…æ˜¾å­˜é—®é¢˜
        "learning_rate": 5e-5,
        "backbone": 'efficientnet_b4',
        "attribute_loss_weight": 1.0
    },
    # å¯ä»¥æ·»åŠ ä¸€ä¸ª"æ‰‹åŠ¨è®¾ç½®"é€‰é¡¹ï¼Œæˆ–è€…é€šè¿‡é€‰æ‹©å…¶ä»–ç­–ç•¥åä¿®æ”¹æ¥è¿›å…¥æ‰‹åŠ¨çŠ¶æ€
    "æ‰‹åŠ¨è®¾ç½® (Manual)": {}
}

# --- ä¾§è¾¹æ ï¼šæ§åˆ¶ä¸å‚æ•°è®¾ç½® ---
st.sidebar.header("âš™ï¸ è®­ç»ƒæ§åˆ¶ä¸­å¿ƒ")

# --- æ–°å¢ï¼štimm å®‰è£…æç¤º --- 
st.sidebar.info("æç¤ºï¼šéƒ¨åˆ†éª¨å¹²ç½‘ç»œä¾èµ– `timm` åº“ã€‚è‹¥é€‰æ‹©æ–°ç½‘ç»œæ— æ•ˆï¼Œè¯·å°è¯•è¿è¡Œ `pip install timm` å®‰è£…ã€‚")

model_name = st.sidebar.text_input("ä¸ºä½ çš„æ¨¡å‹èµ·ä¸ªåå­—", "my_clothes_model")

# --- æ•°æ®é›†è®¾ç½® ---
st.sidebar.subheader("ğŸ’¾ æ•°æ®é›†è·¯å¾„")
# ç§»é™¤æ—§çš„ root_dir è¾“å…¥
# data_root = st.sidebar.text_input("æ•°æ®é›†æ ¹ç›®å½•", ...)

# æ·»åŠ æ–°çš„è¾“å…¥æ¡†ï¼Œä½¿ç”¨ä½ æä¾›çš„è·¯å¾„ä½œä¸ºé»˜è®¤å€¼
anno_dir_input = st.sidebar.text_input(
    "Anno_fine ç›®å½•ç»å¯¹è·¯å¾„", 
    r"E:\AIModels\DeepFashion\DeepFashion\Category and Attribute Prediction Benchmark\Anno_fine",
    help="åŒ…å« train.txt, train_cate.txt ç­‰æ ‡æ³¨æ–‡ä»¶çš„ Anno_fine æ–‡ä»¶å¤¹çš„å®Œæ•´è·¯å¾„ã€‚"
)
img_dir_input = st.sidebar.text_input(
    "é«˜åˆ†è¾¨ç‡å›¾ç‰‡ç›®å½•ç»å¯¹è·¯å¾„", 
    r"E:\AIModels\DeepFashion\DeepFashion\Category and Attribute Prediction Benchmark\Img\img_highres",
    help="åŒ…å« MEN, WOMEN ç­‰å­ç›®å½•çš„é«˜åˆ†è¾¨ç‡å›¾ç‰‡æ–‡ä»¶å¤¹ (å¦‚ img_highres) çš„å®Œæ•´è·¯å¾„ã€‚"
)

# ç®€å•æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
if not os.path.isdir(anno_dir_input):
    st.sidebar.warning(f"è­¦å‘Šï¼šAnno_fine è·¯å¾„ '{anno_dir_input}' ä¸å­˜åœ¨æˆ–ä¸æ˜¯ç›®å½•ã€‚")
if not os.path.isdir(img_dir_input):
    st.sidebar.warning(f"è­¦å‘Šï¼šå›¾ç‰‡ç›®å½•è·¯å¾„ '{img_dir_input}' ä¸å­˜åœ¨æˆ–ä¸æ˜¯ç›®å½•ã€‚")

# --- æ–°å¢ï¼šè®­ç»ƒç­–ç•¥é€‰æ‹© --- 
st.sidebar.subheader("ğŸ¯ è®­ç»ƒç­–ç•¥")
def get_strategy_index():
    # è·å–å½“å‰ session_state ä¸­ç­–ç•¥çš„ç´¢å¼•
    strategy_names = list(STRATEGIES.keys())
    current_strategy = st.session_state.get("selected_strategy", "å‡è¡¡æ¨è (Balanced)")
    try:
        return strategy_names.index(current_strategy)
    except ValueError:
        return 1 # é»˜è®¤è¿”å›å‡è¡¡æ¨èçš„ç´¢å¼•

strategy_choice = st.sidebar.radio(
    "é€‰æ‹©ä¸€ä¸ªé¢„è®¾ç­–ç•¥æˆ–æ‰‹åŠ¨è®¾ç½®:",
    list(STRATEGIES.keys()),
    index=get_strategy_index(), # æ ¹æ® session state è®¾ç½®åˆå§‹é€‰é¡¹
    key="selected_strategy", # ä½¿ç”¨ key ç»‘å®šåˆ° session state
    help="é€‰æ‹©é¢„è®¾ç­–ç•¥ä¼šè‡ªåŠ¨å¡«å……ä¸‹æ–¹å‚æ•°ã€‚é€‰æ‹©åä»å¯æ‰‹åŠ¨ä¿®æ”¹ã€‚æ‰‹åŠ¨è®¾ç½®è¡¨ç¤ºä½¿ç”¨ä¸‹æ–¹å¡«å†™çš„å‚æ•°ã€‚"
)

# æ ¹æ®é€‰æ‹©çš„ç­–ç•¥è·å–é»˜è®¤å€¼
strategy_defaults = STRATEGIES.get(strategy_choice, {})
# å¦‚æœæ˜¯"æ‰‹åŠ¨è®¾ç½®"ï¼Œåˆ™ä¸ä½¿ç”¨ç­–ç•¥é»˜è®¤å€¼ï¼Œå…è®¸ç”¨æˆ·è¾“å…¥æˆ–ä¿ç•™ä¸Šæ¬¡çš„å€¼
is_manual_mode = (strategy_choice == "æ‰‹åŠ¨è®¾ç½® (Manual)")

# --- æ¨¡å‹è®¾ç½® ---
st.sidebar.subheader("ğŸ§  æ¨¡å‹æ¶æ„")
# --- ä¿®æ”¹ï¼šæ·»åŠ æ›´å¤šéª¨å¹²ç½‘ç»œé€‰é¡¹ --- 
backbone_options = (
    'resnet18', 
    'resnet50', 
    'efficientnet_b0', 
    'efficientnet_b3', 
    'efficientnet_b4', 
    'swin_tiny_patch4_window7_224' # Swin Transformer Tiny
)
default_backbone = strategy_defaults.get('backbone', 'efficientnet_b3') if not is_manual_mode else st.session_state.get('backbone_input', 'efficientnet_b3')
# ç¡®ä¿é»˜è®¤å€¼åœ¨é€‰é¡¹åˆ—è¡¨ä¸­ï¼Œå¦‚æœä¸åœ¨ï¼Œåˆ™ä½¿ç”¨åˆ—è¡¨ä¸­çš„ç¬¬ä¸€ä¸ªæˆ–ä¸€ä¸ªå®‰å…¨çš„é»˜è®¤å€¼
if default_backbone not in backbone_options:
    default_backbone_index = 3 # é»˜è®¤ efficientnet_b3 çš„ç´¢å¼•
else:
    default_backbone_index = backbone_options.index(default_backbone)

backbone = st.sidebar.selectbox(
    "é€‰æ‹©éª¨å¹²ç½‘ç»œ", 
    backbone_options,
    index=default_backbone_index,
    key='backbone_input',
    help="é€‰æ‹©ç”¨äºæå–å›¾åƒç‰¹å¾çš„åŸºç¡€ç½‘ç»œç»“æ„ã€‚EfficientNet é€šå¸¸æ•ˆç‡æ›´é«˜ã€‚Swin Transformer æ˜¯è¾ƒæ–°çš„æ¶æ„ã€‚"
)
# pretrained = st.sidebar.checkbox("ä½¿ç”¨é¢„è®­ç»ƒæƒé‡?", True, help="æ¨èå‹¾é€‰ï¼Œä½¿ç”¨åœ¨ ImageNet ä¸Šé¢„è®­ç»ƒçš„æƒé‡å¯ä»¥åŠ å¿«è®­ç»ƒå¹¶æé«˜æ•ˆæœã€‚")
# æš‚æ—¶å¼ºåˆ¶ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œç®€åŒ–é€‰é¡¹
pretrained = True 

# --- è®­ç»ƒå‚æ•° ---
st.sidebar.subheader("â±ï¸ è®­ç»ƒå‚æ•°")
# ä¸ºæ¯ä¸ªå‚æ•°è®¾ç½®é»˜è®¤å€¼ï¼Œä¼˜å…ˆä½¿ç”¨ç­–ç•¥å€¼ï¼Œå¦åˆ™ä½¿ç”¨é€šç”¨é»˜è®¤å€¼æˆ– session_state ä¸­å·²æœ‰çš„å€¼
default_epochs = strategy_defaults.get('epochs', 10) if not is_manual_mode else st.session_state.get('epochs_input', 10)
epochs = st.sidebar.number_input("è®­ç»ƒè½®æ¬¡ (Epochs)", 
                               min_value=1, max_value=100, 
                               value=default_epochs, 
                               key='epochs_input', # æ·»åŠ  key
                               help="æ¨¡å‹å®Œæ•´å­¦ä¹ ä¸€éæ‰€æœ‰è®­ç»ƒæ•°æ®çš„æ¬¡æ•°ã€‚")

default_batch_size = strategy_defaults.get('batch_size', 32) if not is_manual_mode else st.session_state.get('batch_size_input', 32)
batch_size = st.sidebar.number_input("æ‰¹æ¬¡å¤§å° (Batch Size)", 
                                   min_value=1, max_value=256, 
                                   value=default_batch_size, 
                                   key='batch_size_input', # æ·»åŠ  key
                                   help="æ¨¡å‹ä¸€æ¬¡å¤„ç†çš„å›¾ç‰‡æ•°é‡ã€‚æ ¹æ®æ˜¾å­˜å¤§å°è°ƒæ•´ï¼Œè¶Šå¤§é€šå¸¸è¶Šç¨³å®šï¼Œä½†æ›´å æ˜¾å­˜ã€‚")

default_lr = strategy_defaults.get('learning_rate', 1e-4) if not is_manual_mode else st.session_state.get('learning_rate_input', 1e-4)
learning_rate = st.sidebar.number_input(
    "å­¦ä¹ ç‡ (Learning Rate)", 
    min_value=1e-6, max_value=1e-2, 
    value=default_lr, 
    format="%.1e", 
    key='learning_rate_input', # æ·»åŠ  key
    help="æ¨¡å‹å­¦ä¹ çš„é€Ÿåº¦ã€‚å¤ªå¤§ä¼šå¯¼è‡´ä¸ç¨³å®šï¼Œå¤ªå°ä¼šè®­ç»ƒè¿‡æ…¢ã€‚é€šå¸¸ä» 1e-4 æˆ– 1e-3 å¼€å§‹å°è¯•ã€‚"
)

default_attr_weight = strategy_defaults.get('attribute_loss_weight', 1.0) if not is_manual_mode else st.session_state.get('attribute_loss_weight_input', 1.0)
attribute_loss_weight = st.sidebar.slider(
    "å±æ€§æŸå¤±æƒé‡", 
    min_value=0.1, max_value=2.0, 
    value=default_attr_weight, 
    step=0.1, 
    key='attribute_loss_weight_input', # æ·»åŠ  key
    help="è°ƒæ•´ç±»åˆ«ä»»åŠ¡å’Œå±æ€§ä»»åŠ¡çš„é‡è¦æ€§ã€‚å¢åŠ æ­¤å€¼ä¼šè®©æ¨¡å‹æ›´å…³æ³¨å±æ€§è¯†åˆ«ã€‚"
)

# --- è®¾å¤‡ä¸æ‰§è¡Œ ---
st.sidebar.subheader("ğŸ’» è¿è¡Œè®¾å¤‡")
# --- ä¿®æ”¹ï¼šç§»é™¤ 'cpu' é€‰é¡¹ï¼Œé™¤éæ²¡æœ‰ GPU å¯é€‰ --- 
device_options = ['auto'] # 'auto' æ€»æ˜¯å¯ç”¨
device_indices = [] 
gpu_names = {}

if nvml_available and pynvml:
    try:
        device_count = pynvml.nvmlDeviceGetCount()
        if device_count > 0:
            for i in range(device_count):
                handle = pynvml.nvmlDeviceGetHandleByIndex(i)
                try:
                     name = pynvml.nvmlDeviceGetName(handle)
                except Exception as e:
                    name = f"GPU {i}" 
                device_options.append(f'cuda:{i} ({name})')
                device_indices.append(i)
                gpu_names[i] = name
        # else: # å¦‚æœæ²¡æœ‰ GPUï¼Œåˆ™åªä¿ç•™ 'auto'ï¼Œåç»­ä¼šå¤„ç†
        #    pass 
    except pynvml.NVMLError as e:
        st.sidebar.warning(f"è·å– GPU ä¿¡æ¯å¤±è´¥: {e}")
# --- å¦‚æœæ²¡æœ‰ GPU å¯é€‰ï¼Œåˆ™ 'auto' ä¹Ÿæ— æ³•å·¥ä½œï¼Œåé¢ä¼šå¤„ç† --- 
# ç§»é™¤æ·»åŠ  'cpu' çš„è¡Œ
# device_options.append('cpu')

default_device_index = 0 # é»˜è®¤é€‰æ‹© 'auto'
device_choice_display = st.sidebar.selectbox(
    "é€‰æ‹©è¿è¡Œè®¾å¤‡ (éœ€è¦ GPU)", 
    device_options, 
    index=default_device_index, 
    help="'auto' ä¼šè‡ªåŠ¨å°è¯•ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„ GPUã€‚å¿…é¡»é€‰æ‹© GPU è¿›è¡Œè®­ç»ƒã€‚"
)

# è§£æé€‰æ‹©çš„è®¾å¤‡
selected_device = None # åˆå§‹åŒ–ä¸º None
selected_gpu_index = None

if not device_indices and device_choice_display == 'auto':
     # å¦‚æœé€‰äº† auto ä½†å®é™…ä¸Šæ²¡æœ‰ GPU
     st.sidebar.error("é”™è¯¯ï¼šæœªæ£€æµ‹åˆ°å¯ç”¨çš„ NVIDIA GPUã€‚æ— æ³•ä½¿ç”¨ 'auto' æˆ–è¿›è¡Œè®­ç»ƒã€‚")
     # selected_device ä¿æŒ None
elif device_choice_display == 'auto' and device_indices:
     # Auto ä¸”æœ‰ GPUï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ª
     selected_device = f'cuda:{device_indices[0]}' 
     selected_gpu_index = device_indices[0]
elif device_choice_display != 'auto':
     # æ˜ç¡®é€‰æ‹©äº†æŸä¸ª GPU
     try:
         selected_device = device_choice_display.split()[0] # e.g., "cuda:0"
         selected_gpu_index = int(selected_device.split(':')[-1])
         if selected_gpu_index not in device_indices:
             st.sidebar.error(f"é€‰æ‹©çš„ GPU cuda:{selected_gpu_index} ä¸å¯ç”¨ã€‚")
             selected_device = None # æ ‡è®°ä¸ºä¸å¯ç”¨
             selected_gpu_index = None
     except (IndexError, ValueError):
         st.sidebar.error("è§£æ GPU è®¾å¤‡é€‰æ‹©å¤±è´¥ã€‚")
         selected_device = None
         selected_gpu_index = None

st.sidebar.markdown("--- ")

# --- æ§åˆ¶æŒ‰é’® --- 
col_btn_1, col_btn_2 = st.sidebar.columns(2)
start_training = col_btn_1.button("ğŸš€ å¼€å§‹è®­ç»ƒï¼")
stop_training = col_btn_2.button("â¹ï¸ åœæ­¢è®­ç»ƒ")

# å¤„ç†åœæ­¢æŒ‰é’®ç‚¹å‡»
if stop_training:
    st.session_state.stop_requested = True
    st.sidebar.warning("æ”¶åˆ°åœæ­¢è¯·æ±‚...å°†åœ¨å½“å‰è½®æ¬¡ç»“æŸåå°è¯•åœæ­¢ã€‚")

# --- GPU å®æ—¶ç›‘æ§å ä½ç¬¦ ---
st.sidebar.markdown("--- ")
st.sidebar.subheader("ğŸ“ˆ GPU ç›‘æ§")
gpu_info_placeholder = st.sidebar.empty()
# --- æ–°å¢ï¼šGPU å›¾è¡¨å ä½ç¬¦ --- 
gpu_util_chart_placeholder = st.sidebar.empty()
gpu_mem_chart_placeholder = st.sidebar.empty()

# æ›´æ–° GPU ç›‘æ§çš„æ˜¾ç¤ºé€»è¾‘
if not nvml_available:
    gpu_info_placeholder.info("GPU ç›‘æ§ä¸å¯ç”¨ (æœªæ‰¾åˆ° pynvml)ã€‚")
elif not device_indices:
    gpu_info_placeholder.warning("æœªæ£€æµ‹åˆ° NVIDIA GPUï¼Œæ— æ³•è¿›è¡Œç›‘æ§ã€‚")
elif selected_device is None:
    gpu_info_placeholder.error("æœªé€‰æ‹©æˆ–æ— æ³•ç¡®å®šæœ‰æ•ˆçš„ GPU è®¾å¤‡ã€‚")
else:
    # --- ä¿®æ”¹ï¼šä¼ å…¥å›¾è¡¨å ä½ç¬¦ --- 
    gpu_chart_placeholders = (gpu_util_chart_placeholder, gpu_mem_chart_placeholder)
    update_gpu_info(selected_gpu_index, gpu_info_placeholder, gpu_chart_placeholders) 
# --------------------------->

# --- ä¸»åŒºåŸŸï¼šçŠ¶æ€æ˜¾ç¤ºä¸ç»“æœ ---
col_main_1, col_main_2 = st.columns([2, 1]) # çŠ¶æ€/å›¾è¡¨åŒº vs æ—¥å¿—åŒº

with col_main_1:
    st.subheader("ğŸ“Š è®­ç»ƒçŠ¶æ€ä¸æŒ‡æ ‡")
    status_placeholder = st.empty() # ç”¨äºæ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
    overall_progress_bar = st.progress(0.0) # æ•´ä½“ Epoch è¿›åº¦æ¡
    epoch_info_placeholder = st.empty() # æ˜¾ç¤ºæ¯è½®çš„ä¿¡æ¯
    # --- æ–°å¢ï¼šæ—¶é—´ä¿¡æ¯å ä½ç¬¦ --- 
    time_info_placeholder = st.empty()
    # --- æ–°å¢ï¼šæŠ¥å‘Šå’Œæµ‹è¯•å ä½ç¬¦ ---
    diagnostic_report_placeholder = st.empty()
    functional_test_placeholder = st.empty()
    # --- -------------------- ---
    loss_chart_placeholder = st.empty()
    acc_chart_placeholder = st.empty()

with col_main_2:
    st.subheader("ğŸ“œ è®­ç»ƒæ—¥å¿—")
    # --- ä¿®æ”¹ï¼šä½¿ç”¨ st.code ä»£æ›¿ st.text_area --- 
    log_placeholder = st.empty() 
    # åˆå§‹åŒ–æ—¶æ˜¾ç¤ºç©ºçš„ä»£ç å—
    log_placeholder.code("", language='log')

# --- æ–°å¢ï¼šå†å²è®°å½•å¯¹æ¯”åŒºåŸŸ --- 
st.markdown("--- ") # åˆ†éš”çº¿
st.subheader("ğŸ“œ å†å²è®­ç»ƒå¯¹æ¯”")
history_results_placeholder = st.empty()

# å°è¯•åŠ è½½å¹¶æ˜¾ç¤ºå†å²è®°å½•
def display_history():
    all_results = load_results()
    if not all_results:
        history_results_placeholder.info("å°šæœªæœ‰è®­ç»ƒè®°å½•ã€‚")
        return

    # è½¬æ¢æ•°æ®ä»¥ä¾¿æ›´å¥½åœ°æ˜¾ç¤º
    display_data = []
    for r in reversed(all_results): # æ˜¾ç¤ºæœ€æ–°çš„åœ¨å‰é¢
        best_epoch_info = f"{r.get('best_val_loss', 'N/A'):.4f} @ E{r.get('best_epoch', 'N/A')}" if isinstance(r.get('best_val_loss'), (int, float)) else "N/A"
        display_data.append({
            "å®Œæˆæ—¶é—´": r.get("end_time_str", "N/A"),
            "æ¨¡å‹åç§°": r.get("model_name", "N/A"),
            "ç­–ç•¥": r.get("strategy", "N/A"),
            "éª¨å¹²ç½‘ç»œ": r.get("backbone", "N/A"),
            "è½®æ•°": f"{r.get('completed_epochs', 'N/A')}/{r.get('total_epochs', 'N/A')}",
            "æœ€ä½³éªŒè¯æŸå¤± (è½®)": best_epoch_info,
            # "æœ€ä½³éªŒè¯å‡†ç¡®ç‡": f"{r.get('best_val_acc', 'N/A'):.2f}%" if isinstance(r.get('best_val_acc'), (int, float)) else "N/A", # æš‚æ—¶çœç•¥å‡†ç¡®ç‡
            "çŠ¶æ€": r.get("status", "N/A").split('.')[0], # å–ç¬¬ä¸€å¥
            "æ€»è€—æ—¶": r.get("duration_str", "N/A"),
            "æ¨¡å‹è·¯å¾„": r.get("best_model_path", "N/A"),
            "åŠŸèƒ½æµ‹è¯•": r.get("functional_test_result", "æœªæ‰§è¡Œ"),
        })

    results_df = pd.DataFrame(display_data)
    history_results_placeholder.dataframe(results_df, use_container_width=True)

# åœ¨åº”ç”¨åŠ è½½æ—¶å°±æ˜¾ç¤ºå†å²è®°å½•
display_history()
# --- å†å²è®°å½•å¯¹æ¯”åŒºåŸŸç»“æŸ ---

# --- è®­ç»ƒé€»è¾‘è§¦å‘ ---
if start_training:
    # --- æ–°å¢ï¼šå¯åŠ¨å‰æ£€æŸ¥è®¾å¤‡ --- 
    if selected_device is None or not selected_device.startswith('cuda'):
        error_msg = "é”™è¯¯ï¼šå¿…é¡»é€‰æ‹©ä¸€ä¸ªæœ‰æ•ˆçš„ GPU è®¾å¤‡æ‰èƒ½å¼€å§‹è®­ç»ƒã€‚è¯·æ£€æŸ¥ä¾§è¾¹æ çš„è®¾å¤‡é€‰æ‹©ã€‚"
        st.error(error_msg)
        append_log(error_msg)
        status_placeholder.error("âŒ è®­ç»ƒæ— æ³•å¼€å§‹ï¼šæœªé€‰æ‹©æœ‰æ•ˆ GPUã€‚")
        st.stop() # é˜»æ­¢åç»­ä»£ç æ‰§è¡Œ
    # --- è®¾å¤‡æ£€æŸ¥ç»“æŸ ---
    
    # --- é‡ç½®çŠ¶æ€ --- 
    st.session_state.log_messages = [] 
    st.session_state.history_df_list = []
    st.session_state.stop_requested = False
    st.session_state.gpu_error_logged = False
    st.session_state.gpu_metrics_history = []
    st.session_state.gpu_poll_step = 0
    st.session_state.chart_error_logged = False
    # --- æ–°å¢ï¼šé‡ç½®æ—¶é—´çŠ¶æ€ --- 
    st.session_state.training_start_time = time.time() # è®°å½•å¼€å§‹æ—¶é—´
    st.session_state.epoch_durations = []
    # --- æ–°å¢ï¼šæ¸…ç©ºæŠ¥å‘Šå ä½ç¬¦ --- 
    diagnostic_report_placeholder.empty()
    functional_test_placeholder.empty()
    time_info_placeholder.empty()
    gpu_util_chart_placeholder.empty()
    gpu_mem_chart_placeholder.empty()
    
    append_log("è®­ç»ƒè¯·æ±‚å·²æ¥æ”¶ï¼Œå¼€å§‹å‡†å¤‡...")
    status_placeholder.info("â³ æ­£åœ¨å‡†å¤‡è®­ç»ƒç¯å¢ƒ...")
    overall_progress_bar.progress(0.0)
    loss_chart_placeholder.empty()
    acc_chart_placeholder.empty()
    epoch_info_placeholder.empty()
    # --- ä¿®æ”¹ï¼šåˆå§‹åŒ–æ—¥å¿—æ˜¾ç¤º --- 
    log_placeholder.code("\n".join(st.session_state.log_messages), language='log')
    
    if selected_gpu_index is not None:
        update_gpu_info(selected_gpu_index, gpu_info_placeholder, gpu_chart_placeholders)
    # --------------->
    
    # --- æ”¶é›†å‚æ•° --- 
    model_save_dir = os.path.join('.', 'models', model_name)
    os.makedirs(model_save_dir, exist_ok=True) # ç¡®ä¿æ¨¡å‹ä¿å­˜ç›®å½•å­˜åœ¨
    
    args = {
        'epochs': epochs,
        'batch_size': batch_size,
        'learning_rate': learning_rate,
        'device': selected_device, # ç°åœ¨ç¡®è®¤æ˜¯ 'cuda:X' äº†
        'model_save_path': model_save_dir, 
        'attribute_loss_weight': attribute_loss_weight,
        'num_workers': 0 # Windows ä¸‹å¤šè¿›ç¨‹å¯èƒ½æœ‰é—®é¢˜ï¼Œå…ˆç”¨ 0
    }
    append_log(f"ä½¿ç”¨çš„è®­ç»ƒå‚æ•°: {args}") # æ—¥å¿—è®°å½•å®é™…ä½¿ç”¨çš„å‚æ•°
    append_log(f"ä½¿ç”¨çš„éª¨å¹²ç½‘ç»œ: {backbone}")
    append_log(f"Anno Dir Path: {anno_dir_input}")
    append_log(f"Image Dir Path: {img_dir_input}")
    # --------------->

    # --- å®šä¹‰å›¾åƒè½¬æ¢ --- 
    # å¯¹äºé¢„è®­ç»ƒæ¨¡å‹ï¼Œé€šå¸¸ä½¿ç”¨ ImageNet çš„å‡å€¼å’Œæ ‡å‡†å·®
    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                     std=[0.229, 0.224, 0.225])
    # å®šä¹‰è®­ç»ƒå’ŒéªŒè¯çš„è½¬æ¢æµç¨‹
    # TODO: ä»¥åå¯ä»¥æŠŠå›¾åƒå¤§å° (224) ä¹Ÿä½œä¸ºå‚æ•°
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ•°æ®å¢å¼ºï¼Œä¾‹å¦‚ï¼š
        # transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        normalize,
    ])
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        normalize,
    ])
    append_log("å·²å®šä¹‰å›¾åƒè½¬æ¢æµç¨‹ (Resize, ToTensor, Normalize)")

    # --- 1. åˆå§‹åŒ–æ•°æ®é›† ---
    try:
        status_placeholder.info("â³ æ­£åœ¨åŠ è½½æ•°æ®é›†...")
        append_log("åˆå§‹åŒ–è®­ç»ƒæ•°æ®é›†...")
        # !! ä½¿ç”¨æ–°çš„åˆå§‹åŒ–æ–¹å¼ï¼Œä¼ å…¥ç»å¯¹è·¯å¾„ !!
        train_dataset = DeepFashionDataset(
            anno_dir_path=anno_dir_input, 
            image_dir_path=img_dir_input, 
            partition='train', 
            transform=train_transform
        )
        append_log(f"è®­ç»ƒé›†åŠ è½½æˆåŠŸï¼Œæ ·æœ¬æ•°: {len(train_dataset)}")
        
        append_log("åˆå§‹åŒ–éªŒè¯æ•°æ®é›†...")
        # !! ä½¿ç”¨æ–°çš„åˆå§‹åŒ–æ–¹å¼ !!
        val_dataset = DeepFashionDataset(
            anno_dir_path=anno_dir_input, 
            image_dir_path=img_dir_input, 
            partition='val', 
            transform=val_transform
        )
        append_log(f"éªŒè¯é›†åŠ è½½æˆåŠŸï¼Œæ ·æœ¬æ•°: {len(val_dataset)}")
        status_placeholder.success("âœ… æ•°æ®é›†åŠ è½½å®Œæˆ!")
    except FileNotFoundError as e:
        # æ›´æ–°é”™è¯¯æ¶ˆæ¯ä»¥åæ˜ æ–°çš„è·¯å¾„è¾“å…¥
        error_msg = f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°å¿…è¦çš„æ•°æ®æ–‡ä»¶æˆ–ç›®å½•ï¼è¯·æ£€æŸ¥ä½ è¾“å…¥çš„ Anno_fine ç›®å½• '{anno_dir_input}' å’Œå›¾ç‰‡ç›®å½• '{img_dir_input}' æ˜¯å¦æ­£ç¡®ä¸”å­˜åœ¨ã€‚è¯¦ç»†é”™è¯¯: {e}"
        st.error(error_msg)
        append_log(error_msg)
        status_placeholder.error("âŒ æ•°æ®é›†åŠ è½½å¤±è´¥ï¼")
        st.stop()
    except ValueError as e: 
        # æ›´æ–°é”™è¯¯æ¶ˆæ¯
        error_msg = f"é”™è¯¯ï¼šåŠ è½½æˆ–è§£æåˆ†åŒºæ–‡ä»¶æ—¶å‡ºé”™ã€‚è¯·æ£€æŸ¥ '{anno_dir_input}' ç›®å½•ä¸‹çš„åˆ†åŒºæ–‡ä»¶ (å¦‚ train.txt, train_cate.txt) æ˜¯å¦å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®ã€‚è¯¦ç»†é”™è¯¯: {e}"
        st.error(error_msg)
        append_log(error_msg)
        status_placeholder.error("âŒ æ•°æ®é›†åŠ è½½å¤±è´¥ï¼")
        st.stop()
    except Exception as e:
        error_msg = f"é”™è¯¯ï¼šåŠ è½½æ•°æ®é›†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"
        st.error(error_msg)
        append_log(error_msg)
        status_placeholder.error("âŒ æ•°æ®é›†åŠ è½½å¤±è´¥ï¼")
        traceback.print_exc() # æ‰“å°è¯¦ç»†å †æ ˆåˆ°æ§åˆ¶å°
        st.stop()

    # --- 2. åˆå§‹åŒ–æ¨¡å‹ ---
    model = None
    try:
        status_placeholder.info("â³ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
        append_log(f"åˆå§‹åŒ–æ¨¡å‹ (Backbone: {backbone})...") # æ—¥å¿—æ›´æ–°
        num_categories = 50 
        # ä½¿ç”¨ä»ä¸‹æ‹‰æ¡†è·å–çš„ backbone åˆå§‹åŒ–æ¨¡å‹
        model = ClothesModel(
            num_categories=num_categories, 
            backbone=backbone # ç¡®ä¿è¿™é‡Œä¼ é€’çš„æ˜¯æœ€æ–°çš„ backbone å€¼
        )
        append_log(f"æ¨¡å‹åˆå§‹åŒ–æˆåŠŸã€‚å°†æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡: {selected_device}")
        model.to(selected_device)
        status_placeholder.success("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ!")
    except Exception as e:
        error_msg = f"é”™è¯¯ï¼šåˆå§‹åŒ–æ¨¡å‹ '{backbone}' æ—¶å‘ç”Ÿé”™è¯¯: {e}" # åŒ…å« backbone åç§°
        st.error(error_msg)
        append_log(error_msg)
        status_placeholder.error("âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼è¯·æ£€æŸ¥é€‰æ‹©çš„éª¨å¹²ç½‘ç»œæ˜¯å¦å¯ç”¨æˆ–å·²å®‰è£… `timm` åº“ã€‚")
        traceback.print_exc()
        st.stop()
    # ------------------->

    # --- 3. åˆå§‹åŒ– Trainer ---
    try:
        status_placeholder.info("â³ æ­£åœ¨åˆå§‹åŒ–è®­ç»ƒå™¨...")
        append_log("åˆå§‹åŒ– Trainer...")
        trainer = Trainer(model, train_dataset, val_dataset, args)
        append_log("Trainer åˆå§‹åŒ–æˆåŠŸ.")
        status_placeholder.success("âœ… è®­ç»ƒå™¨å‡†å¤‡å°±ç»ª!")
    except Exception as e:
        error_msg = f"é”™è¯¯ï¼šåˆå§‹åŒ– Trainer æ—¶å‘ç”Ÿé”™è¯¯: {e}"
        st.error(error_msg)
        append_log(error_msg)
        status_placeholder.error("âŒ Trainer åˆå§‹åŒ–å¤±è´¥ï¼")
        st.stop()
        
    # --- 4. å¼€å§‹è®­ç»ƒ (é˜»å¡å¼) ---
    append_log("\n==================== å¼€å§‹è®­ç»ƒ ====================")
    status_placeholder.info(f"ğŸš€ æ¨¡å‹è®­ç»ƒä¸­... è®¾å¤‡: {selected_device}")
    start_time = time.time()
    best_val_loss = float('inf')
    training_interrupted = False
    history_df = None # åˆå§‹åŒ– history_df
    training_successful = False # æ ‡è®°è®­ç»ƒæ˜¯å¦æ­£å¸¸å®Œæˆ

    # --- å‡†å¤‡å­˜å‚¨ç»“æœçš„å­—å…¸ --- 
    current_run_result = {
        "start_time": st.session_state.training_start_time,
        "start_time_str": datetime.fromtimestamp(st.session_state.training_start_time).strftime('%Y-%m-%d %H:%M:%S'),
        "model_name": model_name,
        "strategy": strategy_choice,
        "parameters": args, # ä¿å­˜è®­ç»ƒå‚æ•°
        "backbone": backbone,
        "anno_dir": anno_dir_input, # æ˜ç¡®ä¿å­˜Anno_fineç›®å½•è·¯å¾„
        "status": "è¿›è¡Œä¸­",
        "total_epochs": epochs,
        "completed_epochs": 0,
        "best_val_loss": float('inf'),
        "best_epoch": None,
        "best_model_path": None,
        "diagnostic_summary": None, # å¯ä»¥å­˜æŠ¥å‘Šçš„å…³é”®ç‚¹
        "functional_test_result": "æœªæ‰§è¡Œ",
        "end_time": None,
        "end_time_str": None,
        "duration": None,
        "duration_str": None,
    }
    # -------------------------->

    try: 
        for epoch in range(trainer.epochs):
            epoch_start_time = time.time()
            
            # --- æ£€æŸ¥æ˜¯å¦è¯·æ±‚åœæ­¢ --- 
            if st.session_state.get('stop_requested', False):
                append_log("è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­ã€‚")
                status_placeholder.warning("âš ï¸ è®­ç»ƒå·²åœæ­¢ã€‚")
                break # è·³å‡º epoch å¾ªç¯
            # ----------------------->

            status_placeholder.info(f"Epoch {epoch+1}/{trainer.epochs}: æ­£åœ¨è®­ç»ƒ...")
            append_log(f"\n--- å¼€å§‹è®­ç»ƒ Epoch {epoch+1}/{trainer.epochs} ---")
            if selected_gpu_index is not None:
                update_gpu_info(selected_gpu_index, gpu_info_placeholder, gpu_chart_placeholders)
            
            # --- è®­ç»ƒé˜¶æ®µ --- 
            trainer.model.train()
            train_loss, train_correct_cats, train_total_samples = 0.0, 0, 0
            num_batches = len(trainer.train_loader)
            
            for i, batch in enumerate(trainer.train_loader):
                if i % 10 == 0 and st.session_state.get('stop_requested', False):
                     append_log("è®­ç»ƒåœ¨æ‰¹æ¬¡å¤„ç†ä¸­è¢«ä¸­æ–­...")
                     training_interrupted = True
                     break
                try:
                    images = batch['image'].to(trainer.device, non_blocking=True)
                    cat_labels = batch['category'].to(trainer.device, non_blocking=True)
                    attr_labels = batch['attributes'].to(trainer.device, non_blocking=True)
                    trainer.optimizer.zero_grad()
                    cat_logits, attr_logits = trainer.model(images)
                    valid_cat_mask = cat_labels != -1
                    if valid_cat_mask.sum() == 0:
                        loss_cat = torch.tensor(0.0).to(trainer.device)
                    else:
                        loss_cat = trainer.criterion_category(cat_logits[valid_cat_mask], cat_labels[valid_cat_mask])
                    loss_attr = trainer.criterion_attribute(attr_logits, attr_labels)
                    if not (torch.isfinite(loss_cat) and torch.isfinite(loss_attr)):
                        append_log(f"è­¦å‘Š: Epoch {epoch+1}, Batch {i+1}, æ— æ•ˆæŸå¤± (Cat: {loss_cat.item():.4f}, Attr: {loss_attr.item():.4f})ï¼Œè·³è¿‡.")
                        continue
                    loss = loss_cat + trainer.attribute_loss_weight * loss_attr
                    loss.backward()
                    trainer.optimizer.step()
                    
                    batch_size_actual = images.size(0)
                    train_loss += loss.item() * batch_size_actual 
                    if valid_cat_mask.sum() > 0:
                        _, predicted_cats = torch.max(cat_logits.data, 1)
                        train_correct_cats += (predicted_cats[valid_cat_mask] == cat_labels[valid_cat_mask]).sum().item()
                        train_total_samples += valid_cat_mask.sum().item()
                    
                    if (i + 1) % 50 == 0 or (i + 1) == num_batches: # æ¯ 50 ä¸ª batch æˆ–æœ€åä¸€ä¸ª batch æ›´æ–°
                         current_avg_loss = (train_loss / (i + 1)) / batch_size if batch_size > 0 else 0 
                         status_placeholder.info(f"Epoch {epoch+1}/{trainer.epochs}: è®­ç»ƒä¸­... Batch {i+1}/{num_batches} ({(i + 1)*100/num_batches:.0f}%) | Batch Loss: {loss.item():.4f}")
                         # æ›´æ–° GPU ç›‘æ§
                         if selected_gpu_index is not None:
                             update_gpu_info(selected_gpu_index, gpu_info_placeholder, gpu_chart_placeholders)
                except Exception as batch_e:
                    append_log(f"é”™è¯¯: Epoch {epoch+1}, Batch {i+1} å¤„ç†å¤±è´¥: {batch_e}")
                    traceback.print_exc()
                    continue 

            if training_interrupted: break 
            # --- è®­ç»ƒé˜¶æ®µç»“æŸ --->
            
            # --- éªŒè¯é˜¶æ®µ --- 
            avg_val_loss = float('nan') 
            avg_val_cat_acc = float('nan')
            if trainer.val_loader and len(trainer.val_loader.dataset) > 0:
                trainer.model.eval()
                val_loss, val_correct_cats, val_total_samples = 0.0, 0, 0
                with torch.no_grad():
                    for i, batch in enumerate(trainer.val_loader):
                        try:
                            images = batch['image'].to(trainer.device, non_blocking=True)
                            cat_labels = batch['category'].to(trainer.device, non_blocking=True)
                            attr_labels = batch['attributes'].to(trainer.device, non_blocking=True)
                            cat_logits, attr_logits = trainer.model(images)
                            loss_cat = trainer.criterion_category(cat_logits, cat_labels)
                            loss_attr = trainer.criterion_attribute(attr_logits, attr_labels)
                            if not (torch.isfinite(loss_cat) and torch.isfinite(loss_attr)):
                                append_log(f"è­¦å‘Š: Epoch {epoch+1}, éªŒè¯ Batch {i+1}, æ— æ•ˆæŸå¤±ï¼Œè·³è¿‡.")
                                continue
                            loss = loss_cat + trainer.attribute_loss_weight * loss_attr
                            
                            batch_size = images.size(0)
                            val_loss += loss.item() * batch_size
                            _, predicted_cats = torch.max(cat_logits.data, 1)
                            val_correct_cats += (predicted_cats == cat_labels).sum().item()
                            val_total_samples += batch_size
                        except Exception as batch_e:
                             append_log(f"é”™è¯¯: Epoch {epoch+1}, éªŒè¯ Batch {i+1} å¤„ç†å¤±è´¥: {batch_e}")
                             continue # è·³è¿‡å½“å‰æ‰¹æ¬¡

                avg_val_loss = val_loss / val_total_samples if val_total_samples else float('inf')
                avg_val_cat_acc = 100.0 * val_correct_cats / val_total_samples if val_total_samples else 0.0
            else:
                 append_log(f"--- Epoch {epoch+1} æ— éªŒè¯é›†æˆ–éªŒè¯é›†ä¸ºç©ºï¼Œè·³è¿‡éªŒè¯ ---")
            epoch_time = time.time() - epoch_start_time
            append_log(f"--- Epoch {epoch+1} éªŒè¯å®Œæˆ (Avg Loss: {avg_val_loss:.4f}, Cat Acc: {avg_val_cat_acc:.2f}%) --- Time: {epoch_time:.2f}s")
            # --- éªŒè¯é˜¶æ®µç»“æŸ --->

            # --- Epoch ç»“æŸå¤„ç† --- 
            epoch_end_time = time.time()
            epoch_duration = epoch_end_time - epoch_start_time
            st.session_state.epoch_durations.append(epoch_duration)
            
            # --- æ›´æ–° Epoch æ‘˜è¦ã€æ—¥å¿—ã€å›¾è¡¨ã€è¿›åº¦æ¡ã€æ—¶é—´ --- 
            avg_train_loss = train_loss / len(trainer.train_loader.dataset) if len(trainer.train_loader.dataset) > 0 else float('inf')
            avg_train_cat_acc = 100.0 * train_correct_cats / train_total_samples if train_total_samples > 0 else 0.0
            append_log(f"--- Epoch {epoch+1} è®­ç»ƒå®Œæˆ (Avg Loss: {avg_train_loss:.4f}, Cat Acc: {avg_train_cat_acc:.2f}%) ---")
            epoch_summary = (
                f"**Epoch {epoch+1}/{trainer.epochs}** | "
                f"Train Loss: {avg_train_loss:.4f} | Train Acc: {avg_train_cat_acc:.2f}% | "
                f"Val Loss: {avg_val_loss:.4f} | Val Acc: {avg_val_cat_acc:.2f}% | "
                f"Time: {epoch_time:.2f}s"
            )
            epoch_info_placeholder.markdown(epoch_summary)
            current_epoch_history = {
                'epoch': epoch + 1,
                'Train Loss': avg_train_loss if math.isfinite(avg_train_loss) else None, # å¤„ç† Inf
                'Validation Loss': avg_val_loss if math.isfinite(avg_val_loss) else None,
                'Train Accuracy (%)': avg_train_cat_acc,
                'Validation Accuracy (%)': avg_val_cat_acc
            }
            st.session_state.history_df_list.append(current_epoch_history)
            history_df = pd.DataFrame(st.session_state.history_df_list).dropna(subset=['epoch'])
            if not history_df.empty:
                plot_df_loss = history_df[['epoch', 'Train Loss', 'Validation Loss']].set_index('epoch')
                plot_df_acc = history_df[['epoch', 'Train Accuracy (%)', 'Validation Accuracy (%)']].set_index('epoch')
                with loss_chart_placeholder.container():
                     st.line_chart(plot_df_loss)
                with acc_chart_placeholder.container():
                     st.line_chart(plot_df_acc)
            overall_progress_bar.progress((epoch + 1) / trainer.epochs)
            
            # --- æ–°å¢ï¼šæ›´æ–°æ—¶é—´ä¿¡æ¯ --- 
            elapsed_time = epoch_end_time - st.session_state.training_start_time
            avg_epoch_time = sum(st.session_state.epoch_durations) / len(st.session_state.epoch_durations) if st.session_state.epoch_durations else None
            remaining_epochs = trainer.epochs - (epoch + 1)
            eta_seconds = avg_epoch_time * remaining_epochs if avg_epoch_time is not None and remaining_epochs > 0 else None
            estimated_completion_time = datetime.now() + timedelta(seconds=int(eta_seconds)) if eta_seconds is not None else None
            
            time_info_str = (
                f"â±ï¸ **æ—¶é—´ç»Ÿè®¡:**  "
                f"å·²è¿è¡Œ: {format_time_delta(elapsed_time)} | "
                f"å¹³å‡æ¯è½®: {avg_epoch_time:.2f} ç§’ | "
                f"é¢„è®¡å‰©ä½™: {format_time_delta(eta_seconds)} | "
                f"é¢„è®¡å®Œæˆæ—¶é—´: {estimated_completion_time.strftime('%Y-%m-%d %H:%M:%S') if estimated_completion_time else 'N/A'}"
            )
            time_info_placeholder.markdown(time_info_str)
            # --- æ—¶é—´ä¿¡æ¯æ›´æ–°ç»“æŸ ---
            
            log_placeholder.code("\n".join(st.session_state.log_messages), language='log')
            
            if selected_gpu_index is not None:
                update_gpu_info(selected_gpu_index, gpu_info_placeholder, gpu_chart_placeholders)
            
            # --- ä¿å­˜æœ€ä½³æ¨¡å‹ --- 
            if math.isfinite(avg_val_loss) and avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                if trainer.model_save_path:
                    # æ¸…ç†æ—§çš„æœ€ä½³æ¨¡å‹æ–‡ä»¶ï¼Œé¿å…è¿‡å¤šæ–‡ä»¶ç§¯ç´¯
                    for old_file in os.listdir(trainer.model_save_path):
                        if old_file.startswith(f"best_model_{model_name}") and old_file.endswith(".pth"):
                            try:
                                os.remove(os.path.join(trainer.model_save_path, old_file))
                                append_log(f"å·²åˆ é™¤æ—§çš„æœ€ä½³æ¨¡å‹: {old_file}")
                            except OSError as e:
                                append_log(f"æ— æ³•åˆ é™¤æ—§æ¨¡å‹ {old_file}: {e}")
                    # ä¿å­˜æ–°çš„æœ€ä½³æ¨¡å‹
                    save_filename = os.path.join(trainer.model_save_path, f"best_model_{model_name}_epoch{epoch+1}.pth")
                    try:
                        torch.save(trainer.model.state_dict(), save_filename)
                        append_log(f"** æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°: {save_filename} (Val Loss: {avg_val_loss:.4f}) **")
                        best_model_file_path = save_filename # è®°å½•è·¯å¾„
                        current_run_result["best_val_loss"] = avg_val_loss # æ›´æ–°è®°å½•ä¸­çš„æœ€ä½³æŸå¤±
                        current_run_result["best_epoch"] = epoch + 1 # æ›´æ–°è®°å½•ä¸­çš„æœ€ä½³è½®æ¬¡
                        current_run_result["best_model_path"] = best_model_file_path # æ›´æ–°è®°å½•ä¸­çš„è·¯å¾„
                    except Exception as e:
                        append_log(f"é”™è¯¯ï¼šä¿å­˜æ¨¡å‹æ—¶å‡ºé”™: {e}")
                else:
                    append_log("æ¨¡å‹ä¿å­˜è·¯å¾„æœªè®¾ç½®ï¼Œè·³è¿‡ä¿å­˜æœ€ä½³æ¨¡å‹")

            # --- æ›´æ–° Epoch æ‘˜è¦ã€æ—¥å¿—ã€å›¾è¡¨ã€è¿›åº¦æ¡ã€æ—¶é—´ --- 
            current_run_result["completed_epochs"] = epoch + 1 # æ›´æ–°å®Œæˆçš„è½®æ•°
            
            # --- æ–°å¢ï¼šæ›´æ–°æ—¶é—´ä¿¡æ¯ --- 
            elapsed_time = epoch_end_time - st.session_state.training_start_time
            avg_epoch_time = sum(st.session_state.epoch_durations) / len(st.session_state.epoch_durations) if st.session_state.epoch_durations else None
            remaining_epochs = trainer.epochs - (epoch + 1)
            eta_seconds = avg_epoch_time * remaining_epochs if avg_epoch_time is not None and remaining_epochs > 0 else None
            estimated_completion_time = datetime.now() + timedelta(seconds=int(eta_seconds)) if eta_seconds is not None else None
            
            time_info_str = (
                f"â±ï¸ **æ—¶é—´ç»Ÿè®¡:**  "
                f"å·²è¿è¡Œ: {format_time_delta(elapsed_time)} | "
                f"å¹³å‡æ¯è½®: {avg_epoch_time:.2f} ç§’ | "
                f"é¢„è®¡å‰©ä½™: {format_time_delta(eta_seconds)} | "
                f"é¢„è®¡å®Œæˆæ—¶é—´: {estimated_completion_time.strftime('%Y-%m-%d %H:%M:%S') if estimated_completion_time else 'N/A'}"
            )
            time_info_placeholder.markdown(time_info_str)
            # --- æ—¶é—´ä¿¡æ¯æ›´æ–°ç»“æŸ ---
            
            log_placeholder.code("\n".join(st.session_state.log_messages), language='log')
            
            if selected_gpu_index is not None:
                update_gpu_info(selected_gpu_index, gpu_info_placeholder, gpu_chart_placeholders)
            
        # --- Epoch å¾ªç¯ç»“æŸ --->
        training_successful = not training_interrupted # å¦‚æœæ²¡ä¸­æ–­å°±ç®—æˆåŠŸ
        
        # å¦‚æœè®­ç»ƒæˆåŠŸå®Œæˆï¼Œæ›´æ–°çŠ¶æ€ä¸º"å·²å®Œæˆ"
        if training_successful:
            current_run_result["status"] = "å·²å®Œæˆ"
        
    except Exception as e:
        error_msg = f"é”™è¯¯ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"
        st.error(error_msg)
        append_log(error_msg)
        status_placeholder.error("âŒ è®­ç»ƒå¤±è´¥ï¼")
        traceback.print_exc()
        current_run_result["status"] = "é”™è¯¯"
    finally:
        # --- è®­ç»ƒç»“æŸå¤„ç† --- 
        end_time = time.time()
        total_time = end_time - current_run_result["start_time"]
        current_run_result["end_time"] = end_time
        current_run_result["end_time_str"] = datetime.fromtimestamp(end_time).strftime('%Y-%m-%d %H:%M:%S')
        current_run_result["duration"] = total_time
        current_run_result["duration_str"] = format_time_delta(total_time)
        
        append_log(f"æ€»è®­ç»ƒæ—¶é—´: {total_time:.2f} ç§’")
        formatted_best_loss = f"{best_val_loss:.4f}" if math.isfinite(best_val_loss) else "N/A"
        append_log(f"æœ€ä½³éªŒè¯æŸå¤±: {formatted_best_loss}")
        
        # --- æœ€ç»ˆæ—¶é—´ä¿¡æ¯æ›´æ–° --- 
        final_avg_epoch_time = sum(st.session_state.epoch_durations) / len(st.session_state.epoch_durations) if st.session_state.epoch_durations else None
        final_time_info_str = (
                f"â±ï¸ **æœ€ç»ˆç»Ÿè®¡:**  "
                f"æ€»è€—æ—¶: {format_time_delta(total_time)} | "
                f"å¹³å‡æ¯è½®: {final_avg_epoch_time:.2f} ç§’ (å…± {len(st.session_state.epoch_durations)} è½®)"
            )
        time_info_placeholder.markdown(final_time_info_str) 
        
        # --- ä¿®æ”¹ï¼šç¡®ä¿æœ€åä¸€æ¬¡æ›´æ–°æ—¥å¿— --- 
        log_placeholder.code("\n".join(st.session_state.log_messages), language='log')

        # --- ç”ŸæˆæŠ¥å‘Šå’Œæ‰§è¡Œæµ‹è¯• --- 
        history_df = pd.DataFrame(st.session_state.history_df_list).dropna(subset=['epoch'])
        diagnostic_report = ""
        # 1. ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
        if not history_df.empty:
            diagnostic_report = generate_diagnostic_report(history_df, best_val_loss, trainer.epochs)
            diagnostic_report_placeholder.markdown(diagnostic_report)
            append_log("\n--- è¯Šæ–­æŠ¥å‘Šå·²ç”Ÿæˆ ---") # ç®€åŒ–æ—¥å¿—
            # --- ä¿®æ”¹ï¼šå­˜å‚¨æŠ¥å‘Šæ‘˜è¦ --- 
            current_run_result["diagnostic_summary"] = diagnostic_report # å­˜å®Œæ•´æŠ¥å‘Šï¼Œä¹Ÿå¯ä»¥åªå­˜å…³é”®ç‚¹
        else:
            current_run_result["diagnostic_summary"] = "æ— è®­ç»ƒå†å²æ•°æ®"

        # 2. æ‰§è¡ŒåŠŸèƒ½æ¨¡æ‹Ÿæµ‹è¯•
        test_success = False # åˆå§‹åŒ–
        if training_successful and current_run_result["best_model_path"] is not None: # ä½¿ç”¨è®°å½•ä¸­çš„è·¯å¾„
             model_config = {
                 'num_categories': num_categories, 
                 'backbone': backbone 
             }
             # --- ä¿®æ”¹ï¼šä½¿ç”¨è®°å½•çš„æœ€ä½³æ¨¡å‹è·¯å¾„ --- 
             test_report, test_success = run_functional_test(model_save_dir, model_name, model_config, selected_device)
             functional_test_placeholder.markdown(test_report)
             log_summary = "åŠŸèƒ½æµ‹è¯•æˆåŠŸ" if test_success else "åŠŸèƒ½æµ‹è¯•å¤±è´¥"
             append_log(f"\n--- åŠŸèƒ½æ¨¡æ‹Ÿæµ‹è¯• --- \n{log_summary}")
             current_run_result["functional_test_result"] = "æˆåŠŸ" if test_success else "å¤±è´¥"
        elif not training_successful:
             functional_test_placeholder.warning("è®­ç»ƒæœªæˆåŠŸå®Œæˆï¼Œè·³è¿‡åŠŸèƒ½æµ‹è¯•ã€‚")
             append_log("è®­ç»ƒæœªæˆåŠŸå®Œæˆï¼Œè·³è¿‡åŠŸèƒ½æµ‹è¯•ã€‚")
             current_run_result["functional_test_result"] = "è·³è¿‡ (è®­ç»ƒå¤±è´¥)"
        else: 
             functional_test_placeholder.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æœ€ä½³æ¨¡å‹æ–‡ä»¶ï¼Œè·³è¿‡åŠŸèƒ½æµ‹è¯•ã€‚")
             append_log("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æœ€ä½³æ¨¡å‹æ–‡ä»¶ï¼Œè·³è¿‡åŠŸèƒ½æµ‹è¯•ã€‚")
             current_run_result["functional_test_result"] = "è·³è¿‡ (æ— æ¨¡å‹)"

        # --- ä¿å­˜å½“å‰è¿è¡Œç»“æœ --- 
        all_results = load_results()
        all_results.append(current_run_result)
        save_results(all_results)
        append_log(f"å½“å‰è®­ç»ƒç»“æœå·²è¿½åŠ åˆ° {RESULTS_FILE}")
        # --- åˆ·æ–°å†å²è®°å½•æ˜¾ç¤º --- 
        display_history()
        # ------------------------>

        # æ¸…ç† NVML
        if nvml_available and pynvml:
            try:
                pynvml.nvmlShutdown()
            except pynvml.NVMLError as e:
                append_log(f"å…³é—­ NVML æ—¶å‡ºé”™: {e}")

# --- è®­ç»ƒé€»è¾‘è§¦å‘ç»“æŸ ---

# åªæœ‰åœ¨æŒ‰é’®æ²¡æœ‰è¢«ç‚¹å‡»æ—¶ï¼Œæ‰æ˜¾ç¤ºåˆå§‹æç¤º
if not start_training:
    if not st.session_state.get('log_messages'):
        status_placeholder.info("è¯·åœ¨å·¦ä¾§è®¾ç½®å‚æ•°å¹¶ç‚¹å‡» 'å¼€å§‹è®­ç»ƒï¼' æŒ‰é’®ã€‚")
        # --- ä¿®æ”¹ï¼šåˆå§‹åŒ–æ—¥å¿—æ˜¾ç¤º --- 
        log_placeholder.code("å°šæœªå¼€å§‹è®­ç»ƒ...", language='log')
    else:
        # ä¿ç•™ä¸Šæ¬¡è®­ç»ƒçš„æœ€ç»ˆçŠ¶æ€ (æ—¥å¿—å’Œå›¾è¡¨åº”è¯¥è¿˜åœ¨)
        pass 

# --- UI ä»£ç ç»“æŸ --- 