import streamlit as st
import torch
import math
import os
import json
import traceback
import pandas as pd
from datetime import datetime
import re
from utils.file_utils import load_results
from utils.state_manager import append_log

def generate_diagnostic_report(history_df, best_val_loss, total_epochs):
    """æ ¹æ®è®­ç»ƒå†å²ç”Ÿæˆè¯Šæ–­æŠ¥å‘Šå’Œç»“æ„åŒ–è¯„ä¼°ç»“æœ"""
    report = []
    report.append("### ğŸ©º è®­ç»ƒè¯Šæ–­æŠ¥å‘Š")
    
    # åˆ›å»ºä¸€ä¸ªç»“æ„åŒ–ç»“æœå­—å…¸
    result_data = {
        "overfitting_risk": "æœªçŸ¥",
        "loss_diff": float('nan'),
        "accuracy_diff": float('nan'),
        "convergence_status": "æœªçŸ¥",
        "best_epoch": None,
        "best_val_loss": best_val_loss if math.isfinite(best_val_loss) else None,
        "final_val_loss": None,
        "final_val_accuracy": None
    }

    if history_df is None or history_df.empty:
        report.append("- âŒ æ— æ³•ç”ŸæˆæŠ¥å‘Šï¼šç¼ºå°‘è®­ç»ƒå†å²æ•°æ®ã€‚")
        return "\n".join(report), result_data

    final_epoch_data = history_df.iloc[-1]
    best_epoch_data = history_df.loc[history_df['Validation Loss'].idxmin()] if 'Validation Loss' in history_df.columns and history_df['Validation Loss'].notna().any() else None

    # 1. æ•´ä½“è¡¨ç°
    report.append(f"- **è®­ç»ƒè½®æ•°:** {len(history_df)} / {total_epochs}")
    if best_epoch_data is not None:
        best_epoch = int(best_epoch_data['epoch'])
        report.append(f"- **æœ€ä½³éªŒè¯æŸå¤±:** {best_epoch_data['Validation Loss']:.4f} (å‡ºç°åœ¨ Epoch {best_epoch})")
        result_data["best_epoch"] = best_epoch
    else:
        report.append("- **æœ€ä½³éªŒè¯æŸå¤±:** æœªè®°å½•æˆ–æ— æ•ˆã€‚")
    
    result_data["final_val_loss"] = final_epoch_data['Validation Loss']
    result_data["final_val_accuracy"] = final_epoch_data['Validation Accuracy (%)']
    
    report.append(f"- **æœ€ç»ˆéªŒè¯æŸå¤±:** {final_epoch_data['Validation Loss']:.4f}")
    report.append(f"- **æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡:** {final_epoch_data['Validation Accuracy (%)']:.2f}%")

    # 2. æ”¶æ•›æ€§åˆ†æ
    convergence_status = "æœªçŸ¥"
    if len(history_df) >= 5:
        last_5_val_loss = history_df['Validation Loss'].tail(5)
        if last_5_val_loss.is_monotonic_decreasing:
            convergence_status = "æŒç»­æ”¹å–„"
            report.append("- **æ”¶æ•›æ€§:** âœ… éªŒè¯æŸå¤±åœ¨æœ€å5è½®æŒç»­ä¸‹é™ï¼Œå¯èƒ½ä»æœ‰æå‡ç©ºé—´ã€‚")
        elif last_5_val_loss.iloc[-1] < last_5_val_loss.iloc[0]:
            convergence_status = "æ³¢åŠ¨ä¸‹é™"
            report.append("- **æ”¶æ•›æ€§:** âš ï¸ éªŒè¯æŸå¤±åœ¨æœ€å5è½®æœ‰æ‰€æ³¢åŠ¨ï¼Œä½†æ•´ä½“ä»åœ¨ä¸‹é™ã€‚")
        else:
            convergence_status = "å·²æ”¶æ•›æˆ–åœæ»"
            report.append("- **æ”¶æ•›æ€§:** âŒ éªŒè¯æŸå¤±åœ¨æœ€å5è½®æœªèƒ½æŒç»­ä¸‹é™ï¼Œå¯èƒ½å·²æ”¶æ•›æˆ–é‡åˆ°ç“¶é¢ˆã€‚")
    else:
        convergence_status = "è½®æ•°ä¸è¶³"
        report.append("- **æ”¶æ•›æ€§:** âš ï¸ è®­ç»ƒè½®æ•°è¾ƒå°‘ï¼Œéš¾ä»¥åˆ¤æ–­æ”¶æ•›è¶‹åŠ¿ã€‚")
    
    result_data["convergence_status"] = convergence_status

    # 3. è¿‡æ‹Ÿåˆé£é™©
    train_loss_final = final_epoch_data.get('Train Loss', float('nan'))
    val_loss_final = final_epoch_data.get('Validation Loss', float('nan'))
    train_acc_final = final_epoch_data.get('Train Accuracy (%)', float('nan'))
    val_acc_final = final_epoch_data.get('Validation Accuracy (%)', float('nan'))

    loss_diff = abs(train_loss_final - val_loss_final) if math.isfinite(train_loss_final) and math.isfinite(val_loss_final) else float('inf')
    acc_diff = abs(train_acc_final - val_acc_final) if math.isfinite(train_acc_final) and math.isfinite(val_acc_final) else float('inf')
    
    result_data["loss_diff"] = loss_diff
    result_data["accuracy_diff"] = acc_diff

    # è®¾å®šè¿‡æ‹Ÿåˆé£é™©é˜ˆå€¼
    overfitting_risk = "ä½"
    risk_details = []
    
    if loss_diff > 0.5:
        risk_details.append(f"æŸå¤±å·®å¼‚({loss_diff:.2f})å¤§äº0.5")
        overfitting_risk = "é«˜"
    elif loss_diff > 0.2:
        risk_details.append(f"æŸå¤±å·®å¼‚({loss_diff:.2f})å¤§äº0.2")
        overfitting_risk = "ä¸­"
        
    if acc_diff > 15:
        risk_details.append(f"å‡†ç¡®ç‡å·®å¼‚({acc_diff:.1f}%)å¤§äº15%")
        overfitting_risk = "é«˜"
    elif acc_diff > 8:
        risk_details.append(f"å‡†ç¡®ç‡å·®å¼‚({acc_diff:.1f}%)å¤§äº8%")
        if overfitting_risk != "é«˜":
            overfitting_risk = "ä¸­"
    
    result_data["overfitting_risk"] = overfitting_risk
    
    # æ ¼å¼åŒ–é£é™©è¯¦æƒ…
    risk_detail_text = "ï¼Œ".join(risk_details) if risk_details else "è®­ç»ƒé›†å’ŒéªŒè¯é›†è¡¨ç°ç›¸è¿‘"
    
    report.append(f"- **è¿‡æ‹Ÿåˆé£é™©:** {overfitting_risk} ")
    report.append(f"  - **æŸå¤±å·®å¼‚:** {loss_diff:.2f} | **å‡†ç¡®ç‡å·®å¼‚:** {acc_diff:.1f}%") 
    report.append(f"  - **åŸå› :** {risk_detail_text}")
    
    if overfitting_risk != "ä½":
        recommendation = ""
        if overfitting_risk == "é«˜":
            recommendation = "å»ºè®®: å¢å¼ºæ­£åˆ™åŒ–(å¢åŠ dropoutæˆ–æƒé‡è¡°å‡)ã€å¢åŠ æ•°æ®å¢å¼ºæˆ–ç¼©å°æ¨¡å‹è§„æ¨¡"
        else:  # ä¸­é£é™©
            recommendation = "å»ºè®®: è€ƒè™‘é€‚å½“å¢åŠ æ­£åˆ™åŒ–æˆ–æå‰åœæ­¢è®­ç»ƒ"
        report.append(f"  - _{recommendation}_")

    return "\n".join(report), result_data

def run_functional_test(model_save_dir, model_name, model_config, device):
    """å°è¯•åŠ è½½æœ€ä½³æ¨¡å‹å¹¶è¿›è¡Œä¸€æ¬¡æ¨¡æ‹Ÿæ¨ç†ï¼ŒåŒæ—¶æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶"""
    report = ["### âš™ï¸ åŠŸèƒ½æ¨¡æ‹Ÿæµ‹è¯•"]
    best_model_file = None
    metadata_file = None
    error_details = {}
    
    try:
        # æ£€æŸ¥å‚æ•°æœ‰æ•ˆæ€§
        if not model_save_dir:
            report.append("- âŒ æ¨¡å‹ä¿å­˜ç›®å½•ä¸ºç©º")
            error_details["error_type"] = "empty_save_dir"
            error_details["message"] = "æ¨¡å‹ä¿å­˜ç›®å½•ä¸ºç©ºï¼Œæ— æ³•è¿›è¡ŒåŠŸèƒ½æµ‹è¯•"
            error_details["solution"] = "è¯·ç¡®ä¿å·²æŒ‡å®šæœ‰æ•ˆçš„æ¨¡å‹ä¿å­˜ç›®å½•"
            return "\n".join(report), False, error_details
            
        if not os.path.exists(model_save_dir):
            report.append(f"- âŒ æ¨¡å‹ä¿å­˜ç›®å½•ä¸å­˜åœ¨: {model_save_dir}")
            error_details["error_type"] = "dir_not_found"
            error_details["message"] = f"æŒ‡å®šçš„æ¨¡å‹ä¿å­˜ç›®å½•ä¸å­˜åœ¨: {model_save_dir}"
            error_details["solution"] = "è¯·æ£€æŸ¥æ¨¡å‹ä¿å­˜è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œå¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹"
            return "\n".join(report), False, error_details
            
        if not model_name:
            report.append("- âŒ æ¨¡å‹åç§°ä¸ºç©º")
            error_details["error_type"] = "empty_model_name"
            error_details["message"] = "æ¨¡å‹åç§°ä¸ºç©ºï¼Œæ— æ³•å®šä½æ¨¡å‹æ–‡ä»¶"
            error_details["solution"] = "è¯·ç¡®ä¿æ¨¡å‹åç§°å·²æ­£ç¡®è®¾ç½®" 
            return "\n".join(report), False, error_details
            
        if not model_config:
            report.append("- âŒ æ¨¡å‹é…ç½®ä¸ºç©º")
            error_details["error_type"] = "empty_config"
            error_details["message"] = "æ¨¡å‹é…ç½®ä¸ºç©ºï¼Œæ— æ³•åˆå§‹åŒ–æ¨¡å‹"
            error_details["solution"] = "è¯·æä¾›æœ‰æ•ˆçš„æ¨¡å‹é…ç½®" 
            return "\n".join(report), False, error_details
        
        # æå–æ¨¡å‹åç§°çš„åŸºç¡€éƒ¨åˆ†ï¼Œå¿½ç•¥å¯èƒ½çš„æ—¶é—´æˆ³
        # ä¾‹å¦‚ï¼šä» "MD_RESNET18_5_64_50E04_0503_1137" æå– "MD_RESNET18_5_64_50E04"
        base_model_name = model_name
        # å¦‚æœæœ‰æ—¶é—´æˆ³æ ¼å¼ (_MMDD_HHMM)ï¼Œå»é™¤å®ƒ
        time_stamp_pattern = r'_\d{4}_\d{4}$'
        base_model_name = re.sub(time_stamp_pattern, '', base_model_name)
        
        # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶çš„æ–¹å¼æ›´çµæ´»
        try:
            all_files = os.listdir(model_save_dir)
        except Exception as e:
            report.append(f"- âŒ æ— æ³•è¯»å–æ¨¡å‹ç›®å½•: {e}")
            error_details["error_type"] = "directory_read_error"
            error_details["message"] = f"è¯»å–æ¨¡å‹ç›®å½•æ—¶å‡ºé”™: {e}"
            error_details["solution"] = "è¯·æ£€æŸ¥æ¨¡å‹ç›®å½•æƒé™æˆ–æ˜¯å¦å¯è®¿é—®"
            return "\n".join(report), False, error_details
            
        # 1. é¦–å…ˆå°è¯•å®Œå…¨åŒ¹é…
        possible_files = [f for f in all_files if f.startswith(f"best_model_{model_name}") and f.endswith(".pth")]
        
        # 2. å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•ä½¿ç”¨åŸºç¡€åç§°éƒ¨åˆ†åŒ¹é…
        if not possible_files:
            possible_files = [f for f in all_files if f.startswith(f"best_model_{base_model_name}") and f.endswith(".pth")]
            
        # 3. å¦‚æœè¿˜æ‰¾ä¸åˆ°ï¼Œå°è¯•æ›´å®½æ¾çš„åŒ¹é…ï¼ˆé€‚ç”¨äºåç§°è¢«æˆªæ–­çš„æƒ…å†µï¼‰
        if not possible_files and len(base_model_name) > 15:
            short_name = base_model_name[:15]  # å–å‰15ä¸ªå­—ç¬¦
            possible_files = [f for f in all_files if f.startswith(f"best_model_{short_name}") and f.endswith(".pth")]
        
        # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½æ‰¾ä¸åˆ°æ–‡ä»¶
        if not possible_files:
            report.append("- âŒ æœªæ‰¾åˆ°ä¿å­˜çš„æœ€ä½³æ¨¡å‹æ–‡ä»¶ã€‚")
            error_details["error_type"] = "missing_model_file"
            error_details["message"] = f"æ— æ³•åœ¨ {model_save_dir} ä¸­æ‰¾åˆ°ä¸ '{model_name}' ç›¸å…³çš„æ¨¡å‹æ–‡ä»¶"
            error_details["solution"] = "è¯·æ£€æŸ¥è®­ç»ƒæ˜¯å¦æˆåŠŸå®Œæˆï¼Œæˆ–è€…æ¨¡å‹æ–‡ä»¶æ˜¯å¦è¢«æ„å¤–åˆ é™¤ã€‚å¯ä»¥å°è¯•é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚"
            return "\n".join(report), False, error_details
            
        # å¦‚æœæœ‰å¤šä¸ªåŒ¹é…æ–‡ä»¶ï¼Œé€‰æ‹©æœ€æ–°çš„ä¸€ä¸ªï¼ˆæŒ‰epochæ’åºï¼‰
        try:
            # é¦–å…ˆå°è¯•æå–epochç¼–å·è¿›è¡Œæ’åº
            possible_files.sort(key=lambda x: int(x.split('_epoch')[-1].split('.')[0]), reverse=True)
        except (IndexError, ValueError):
            # å¦‚æœæ— æ³•æå–epochç¼–å·ï¼Œåˆ™æŒ‰æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ’åº
            possible_files.sort(key=lambda x: os.path.getmtime(os.path.join(model_save_dir, x)), reverse=True)
        
        best_model_file = os.path.join(model_save_dir, possible_files[0])
        report.append(f"- æ‰¾åˆ°æœ€ä½³æ¨¡å‹æ–‡ä»¶: `{best_model_file}`")
        
        # åŒæ ·ä½¿ç”¨æ›´çµæ´»çš„æ–¹å¼æŸ¥æ‰¾å…ƒæ•°æ®æ–‡ä»¶
        possible_metadata_files = [
            os.path.join(model_save_dir, f"{model_name}_metadata.json"),
            os.path.join(model_save_dir, f"{base_model_name}_metadata.json")
        ]
        
        metadata_file = None
        for meta_path in possible_metadata_files:
            if meta_path and os.path.exists(meta_path):  # æ·»åŠ å¯¹meta_pathéNoneçš„æ£€æŸ¥
                metadata_file = meta_path
                break

        # è¯»å–å¹¶æ˜¾ç¤ºåŸºæœ¬å…ƒæ•°æ®ä¿¡æ¯
        if metadata_file and os.path.exists(metadata_file):  # æ·»åŠ å¯¹metadata_fileéNoneçš„æ£€æŸ¥
            report.append(f"- âœ… æ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶: `{metadata_file}`")
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                report.append("- å…ƒæ•°æ®æ¦‚è¦:")
                report.append(f"  - æ¨¡å‹åç§°: {metadata.get('model_name', 'æœªå®šä¹‰')}")
                report.append(f"  - ç‰ˆæœ¬: {metadata.get('version', 'æœªå®šä¹‰')}")
                report.append(f"  - æ¶æ„: {metadata.get('architecture', 'æœªå®šä¹‰')}")
                report.append(f"  - è¾“å…¥å½¢çŠ¶: {metadata.get('input_shape', 'æœªå®šä¹‰')}")
                report.append(f"  - æ”¯æŒç±»åˆ«æ•°: {len(metadata.get('class_names', []))} ç±»")
                report.append(f"  - æ”¯æŒç‰¹å¾æ•°: {len(metadata.get('feature_names', []))} é¡¹")
                report.append(f"  - åˆ›å»ºæ—¥æœŸ: {metadata.get('date_created', 'æœªå®šä¹‰')}")
            except Exception as e:
                report.append(f"- âš ï¸ è¯»å–å…ƒæ•°æ®æ–‡ä»¶å‡ºé”™: {e}")
                report.append(f"  - å¯èƒ½åŸå› : å…ƒæ•°æ®æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®æˆ–æŸå")
                report.append(f"  - å»ºè®®è§£å†³æ–¹æ¡ˆ: é‡æ–°ç”Ÿæˆå…ƒæ•°æ®æ–‡ä»¶")
                error_details["error_type"] = "metadata_read_error"
                error_details["message"] = f"è¯»å–å…ƒæ•°æ®æ–‡ä»¶æ—¶å‡ºé”™: {e}"
                error_details["solution"] = "å…ƒæ•°æ®æ–‡ä»¶å¯èƒ½å·²æŸåï¼Œè¯·å°è¯•ä½¿ç”¨'æ‰¹é‡ç”Ÿæˆç¼ºå¤±çš„å…ƒæ•°æ®'åŠŸèƒ½é‡æ–°ç”Ÿæˆã€‚"
        else:
            report.append("- âš ï¸ æœªæ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶ï¼Œè¿™å¯èƒ½ä¼šå½±å“æ¨¡å‹çš„å¯ç”¨æ€§ã€‚")
            report.append("  - è§£å†³æ–¹æ¡ˆ: ç‚¹å‡»'æ‰¹é‡ç”Ÿæˆç¼ºå¤±çš„å…ƒæ•°æ®'æŒ‰é’®æˆ–ä½¿ç”¨æ¨¡å‹ç®¡ç†ç•Œé¢ç”Ÿæˆå…ƒæ•°æ®")
            error_details["missing_metadata"] = True

        # åŠ è½½æ¨¡å‹
        report.append("- å°è¯•åŠ è½½æ¨¡å‹...")
        try:
            from model import ClothesModel
            model = ClothesModel(num_categories=model_config['num_categories'], backbone=model_config['backbone'])
        except Exception as model_init_error:
            report.append(f"- âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {model_init_error}")
            report.append("  - å¯èƒ½åŸå› : æ¨¡å‹ç±»å®šä¹‰å·²æ›´æ”¹æˆ–å‚æ•°ä¸åŒ¹é…")
            report.append("  - å»ºè®®è§£å†³æ–¹æ¡ˆ: è¯·æ£€æŸ¥æ¨¡å‹é…ç½®ï¼Œç¡®ä¿backboneå‚æ•°æ­£ç¡®")
            error_details["error_type"] = "model_init_error"
            error_details["message"] = f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {model_init_error}"
            error_details["solution"] = "è¯·æ£€æŸ¥æ¨¡å‹é…ç½®ï¼Œå°¤å…¶æ˜¯backboneå‚æ•°æ˜¯å¦æ­£ç¡®ã€‚å¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚"
            return "\n".join(report), False, error_details
            
        try:
            model.load_state_dict(torch.load(best_model_file, map_location=device))
        except Exception as load_error:
            report.append(f"- âŒ æ¨¡å‹æƒé‡åŠ è½½å¤±è´¥: {load_error}")
            report.append("  - å¯èƒ½åŸå› : æ¨¡å‹æ–‡ä»¶æŸåæˆ–æ¨¡å‹ç»“æ„ä¸ä¿å­˜æ—¶ä¸ä¸€è‡´")
            report.append("  - å»ºè®®è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´ï¼Œå¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹")
            error_details["error_type"] = "model_load_error"
            error_details["message"] = f"æ¨¡å‹æƒé‡åŠ è½½å¤±è´¥: {load_error}"
            error_details["solution"] = "æ¨¡å‹æ–‡ä»¶å¯èƒ½å·²æŸåæˆ–ä¸å½“å‰ä»£ç ä¸å…¼å®¹ã€‚è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§ï¼Œå¿…è¦æ—¶é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚"
            return "\n".join(report), False, error_details
            
        model.to(device)
        model.eval()
        report.append("- âœ… æ¨¡å‹åŠ è½½æˆåŠŸã€‚")

        # æ¨¡æ‹Ÿæ¨ç†
        report.append("- å°è¯•æ¨¡æ‹Ÿæ¨ç†...")
        # åˆ›å»ºè™šæ‹Ÿè¾“å…¥ (batch_size=1, channels=3, height=224, width=224)
        try:
            dummy_input = torch.randn(1, 3, 224, 224).to(device)
            with torch.no_grad():
                cat_logits, attr_logits = model(dummy_input)
        except RuntimeError as rt_error:
            # CUDAå†…å­˜ä¸è¶³
            if "CUDA out of memory" in str(rt_error):
                report.append(f"- âŒ æ¨ç†å¤±è´¥: GPUå†…å­˜ä¸è¶³")
                report.append("  - åŸå› : å½“å‰GPUå†…å­˜ä¸è¶³ä»¥è¿è¡Œæ­¤æ¨¡å‹")
                report.append("  - å»ºè®®è§£å†³æ–¹æ¡ˆ: å…³é—­å…¶ä»–å ç”¨GPUå†…å­˜çš„åº”ç”¨ï¼Œæˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹")
                error_details["error_type"] = "cuda_oom_error"
                error_details["message"] = f"GPUå†…å­˜ä¸è¶³: {rt_error}"
                error_details["solution"] = "è¯·å°è¯•å…³é—­å…¶ä»–å ç”¨GPUå†…å­˜çš„åº”ç”¨ç¨‹åºï¼Œæˆ–è€…ä½¿ç”¨å†…å­˜å ç”¨æ›´å°çš„backboneã€‚"
            else:
                report.append(f"- âŒ æ¨ç†è¿‡ç¨‹ä¸­å‡ºç°è¿è¡Œæ—¶é”™è¯¯: {rt_error}")
                report.append("  - å¯èƒ½åŸå› : æ¨¡å‹ç»“æ„ä¸è®­ç»ƒæ—¶ä¸ä¸€è‡´æˆ–è¾“å…¥æ ¼å¼é—®é¢˜")
                report.append("  - å»ºè®®è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥æ¨¡å‹é…ç½®ï¼Œç¡®ä¿backboneå‚æ•°æ­£ç¡®")
                error_details["error_type"] = "inference_runtime_error"
                error_details["message"] = f"æ¨ç†è¿‡ç¨‹ä¸­å‡ºç°è¿è¡Œæ—¶é”™è¯¯: {rt_error}"
                error_details["solution"] = "è¯·æ£€æŸ¥æ¨¡å‹é…ç½®ä¸è®­ç»ƒæ—¶æ˜¯å¦ä¸€è‡´ï¼Œå°¤å…¶æ˜¯backboneå‚æ•°ã€‚å¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚"
            return "\n".join(report), False, error_details
        except Exception as infer_error:
            report.append(f"- âŒ æ¨ç†å¤±è´¥: {infer_error}")
            report.append("  - å¯èƒ½åŸå› : æ¨¡å‹ç»“æ„é—®é¢˜æˆ–å†…éƒ¨é”™è¯¯")
            report.append("  - å»ºè®®è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥æ¨¡å‹ä»£ç ï¼Œå¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹")
            error_details["error_type"] = "inference_error"
            error_details["message"] = f"æ¨ç†å¤±è´¥: {infer_error}"
            error_details["solution"] = "æ¨¡å‹å†…éƒ¨å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ¨¡å‹ä»£ç æˆ–å°è¯•é‡æ–°è®­ç»ƒã€‚"
            return "\n".join(report), False, error_details
        
        # æ£€æŸ¥è¾“å‡º
        report.append(f"- æ¨¡å‹è¾“å‡º (ç±»åˆ« Logits): {cat_logits.shape}")
        report.append(f"- æ¨¡å‹è¾“å‡º (å±æ€§ Logits): {attr_logits.shape}")
        
        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        expected_categories = model_config['num_categories']
        expected_attributes = 26  # å›ºå®š26ä¸ªå±æ€§
        
        shape_errors = []
        if cat_logits.shape[0] != 1:
            shape_errors.append(f"ç±»åˆ«è¾“å‡ºæ‰¹æ¬¡ç»´åº¦é”™è¯¯: æœŸæœ›1ï¼Œå®é™…{cat_logits.shape[0]}")
        if cat_logits.shape[1] != expected_categories:
            shape_errors.append(f"ç±»åˆ«æ•°é‡é”™è¯¯: æœŸæœ›{expected_categories}ï¼Œå®é™…{cat_logits.shape[1]}")
        if attr_logits.shape[0] != 1:
            shape_errors.append(f"å±æ€§è¾“å‡ºæ‰¹æ¬¡ç»´åº¦é”™è¯¯: æœŸæœ›1ï¼Œå®é™…{attr_logits.shape[0]}")
        if attr_logits.shape[1] != expected_attributes:
            shape_errors.append(f"å±æ€§æ•°é‡é”™è¯¯: æœŸæœ›{expected_attributes}ï¼Œå®é™…{attr_logits.shape[1]}")
            
        if shape_errors:
            report.append("- âŒ æ¨¡æ‹Ÿæ¨ç†å®Œæˆï¼Œä½†è¾“å‡ºå½¢çŠ¶ä¸ç¬¦åˆé¢„æœŸï¼")
            for err in shape_errors:
                report.append(f"  - {err}")
            report.append("  - å¯èƒ½åŸå› : æ¨¡å‹è®­ç»ƒæ—¶çš„ç±»åˆ«æˆ–å±æ€§æ•°é‡é…ç½®ä¸å½“å‰ä¸ä¸€è‡´")
            report.append("  - å»ºè®®è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥è®­ç»ƒé…ç½®ï¼Œç¡®ä¿ç±»åˆ«æ•°é‡å’Œå±æ€§æ•°é‡æ­£ç¡®è®¾ç½®")
            error_details["error_type"] = "output_shape_error"
            error_details["message"] = "æ¨¡å‹è¾“å‡ºå½¢çŠ¶ä¸ç¬¦åˆé¢„æœŸ"
            error_details["details"] = shape_errors
            error_details["solution"] = "æ¨¡å‹è¾“å‡ºå°ºå¯¸ä¸é¢„æœŸä¸ç¬¦ï¼Œå¯èƒ½æ˜¯è®­ç»ƒé…ç½®ä¸å½“å‰ä¸åŒ¹é…ã€‚è¯·æ£€æŸ¥æ¨¡å‹é…ç½®ï¼Œå°¤å…¶æ˜¯ç±»åˆ«æ•°é‡è®¾ç½®ã€‚"
            return "\n".join(report), False, error_details
        else:
            report.append("- âœ… æ¨¡æ‹Ÿæ¨ç†æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶ç¬¦åˆé¢„æœŸã€‚")
             
        # æ£€æŸ¥æ˜¯å¦æœ‰å…ƒæ•°æ®å’Œæ¨¡å‹ï¼Œå…¨éƒ¨æˆåŠŸæ‰è¿”å›æˆåŠŸ
        if os.path.exists(metadata_file):
            report.append("- ğŸ‰ åŠŸèƒ½æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼æ¨¡å‹å¯ä»¥æ­£å¸¸åŠ è½½å’Œæ¨ç†ï¼Œå…ƒæ•°æ®æ–‡ä»¶é½å…¨ã€‚")
            return "\n".join(report), True, {}
        else:
            report.append("- âš ï¸ åŠŸèƒ½æµ‹è¯•éƒ¨åˆ†æˆåŠŸï¼Œä½†ç¼ºå°‘å…ƒæ•°æ®æ–‡ä»¶ã€‚")
            report.append("  - å»ºè®®: ç‚¹å‡»'æ‰¹é‡ç”Ÿæˆç¼ºå¤±çš„å…ƒæ•°æ®'æŒ‰é’®ç”Ÿæˆç¼ºå¤±çš„å…ƒæ•°æ®æ–‡ä»¶")
            error_details["error_type"] = "missing_metadata"
            error_details["message"] = "æ¨¡å‹å¯ä»¥æ­£å¸¸åŠ è½½å’Œä½¿ç”¨ï¼Œä½†ç¼ºå°‘å…ƒæ•°æ®æ–‡ä»¶"
            error_details["solution"] = "è¯·ä½¿ç”¨'æ‰¹é‡ç”Ÿæˆç¼ºå¤±çš„å…ƒæ•°æ®'åŠŸèƒ½ç”Ÿæˆå…ƒæ•°æ®æ–‡ä»¶ã€‚"
            return "\n".join(report), False, error_details

    except Exception as e:
        error_trace = traceback.format_exc()
        report.append(f"- âŒ åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        report.append(f"- é”™è¯¯ç±»å‹: {type(e).__name__}")
        report.append("- å¯èƒ½åŸå› :")
        
        if "No such file or directory" in str(e):
            report.append("  - æ–‡ä»¶æˆ–ç›®å½•ä¸å­˜åœ¨ï¼Œæ¨¡å‹æ–‡ä»¶æˆ–ç›®å½•å¯èƒ½å·²è¢«åˆ é™¤")
            report.append("  - å»ºè®®è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å’Œç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œå¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹")
            error_details["error_type"] = "file_not_found"
        elif "CUDA out of memory" in str(e):
            report.append("  - GPUå†…å­˜ä¸è¶³ï¼Œæ— æ³•åŠ è½½æˆ–è¿è¡Œæ¨¡å‹")
            report.append("  - å»ºè®®è§£å†³æ–¹æ¡ˆ: å…³é—­å…¶ä»–å ç”¨GPUå†…å­˜çš„åº”ç”¨ï¼Œæˆ–ä½¿ç”¨CPUæ¨¡å¼")
            error_details["error_type"] = "cuda_oom"
        elif "ModuleNotFoundError" in error_trace:
            report.append("  - ç¼ºå°‘å¿…è¦çš„Pythonæ¨¡å—")
            report.append("  - å»ºè®®è§£å†³æ–¹æ¡ˆ: å®‰è£…ç¼ºå¤±çš„ä¾èµ–åŒ…")
            error_details["error_type"] = "missing_module"
        elif "KeyError" in error_trace:
            report.append("  - æ¨¡å‹å‚æ•°é”®é”™è¯¯ï¼Œæ¨¡å‹ç»“æ„å¯èƒ½ä¸ä¿å­˜æ—¶ä¸ä¸€è‡´")
            report.append("  - å»ºè®®è§£å†³æ–¹æ¡ˆ: ç¡®ä¿ä½¿ç”¨ç›¸åŒç‰ˆæœ¬çš„ä»£ç åŠ è½½æ¨¡å‹ï¼Œæˆ–é‡æ–°è®­ç»ƒæ¨¡å‹")
            error_details["error_type"] = "model_key_error"
        else:
            report.append("  - æœªçŸ¥é”™è¯¯ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯")
            report.append("  - å»ºè®®è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥ç¯å¢ƒé…ç½®ï¼Œæ¨¡å‹æ–‡ä»¶ï¼Œå¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹")
            error_details["error_type"] = "unknown_error"
            
        error_details["message"] = str(e)
        error_details["solution"] = "è¯·æ ¹æ®é”™è¯¯è¯¦æƒ…é‡‡å–å¯¹åº”è§£å†³æ–¹æ¡ˆï¼Œå¿…è¦æ—¶å¯å°è¯•é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚"
        append_log(f"åŠŸèƒ½æµ‹è¯•å¤±è´¥: {error_trace}")
        return "\n".join(report), False, error_details

def generate_metadata_for_model(model_result):
    """ä¸ºå•ä¸ªæ¨¡å‹ç”Ÿæˆå…ƒæ•°æ®æ–‡ä»¶"""
    try:
        model_name = model_result.get("model_name", "")
        model_path = model_result.get("best_model_path", "")
        
        if not model_name:
            return False, "æ¨¡å‹åç§°ä¸ºç©º"
            
        if not model_path:
            return False, "æ¨¡å‹è·¯å¾„ä¸ºç©º"
            
        if not os.path.exists(model_path):
            return False, f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}"
        
        # æå–æ¨¡å‹ç›®å½•
        model_dir = os.path.dirname(model_path)
        if not model_dir:
            return False, "æ— æ³•æå–æ¨¡å‹ç›®å½•"
            
        # å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        metadata_file = os.path.join(model_dir, f"{model_name}_metadata.json")
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if metadata_file and os.path.exists(metadata_file):
            return True, "å…ƒæ•°æ®å·²å­˜åœ¨"
        
        # ä»è®­ç»ƒç»“æœä¸­æå–åŸºæœ¬ä¿¡æ¯
        backbone = model_result.get("backbone", "unknown")
        num_categories = model_result.get("num_categories", 13)
        input_size = model_result.get("image_size", 224)
        learning_rate = model_result.get("learning_rate", 0.0001)
        batch_size = model_result.get("batch_size", 32)
        total_epochs = model_result.get("total_epochs", 50)
        
        # å®Œæˆçš„è®­ç»ƒè½®æ•°
        completed_epochs = model_result.get("completed_epochs", 0)
        
        # æŸ¥æ‰¾æ€§èƒ½æŒ‡æ ‡
        best_val_loss = model_result.get("best_val_loss", 0.0)
        best_val_acc = model_result.get("best_val_accuracy", 0.0)
        best_epoch = model_result.get("best_epoch", 0)
        
        # é»˜è®¤çš„ç±»åˆ«å’Œç‰¹å¾
        # è¿™äº›å¯ä»¥ä»å…¶ä»–åœ°æ–¹å¯¼å…¥ï¼Œä½†ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œç¡¬ç¼–ç 
        from utils.state_manager import get_default_categories, get_default_features
        class_names = get_default_categories()
        feature_names = get_default_features()
        
        # åˆ›å»ºå…ƒæ•°æ®å­—å…¸
        metadata = {
            "model_name": model_name,
            "version": "1.0",
            "date_created": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "architecture": f"ClothesModel({backbone})",
            "input_shape": [3, input_size, input_size],
            "preprocessing": {
                "mean": [0.485, 0.456, 0.406],
                "std": [0.229, 0.224, 0.225],
                "resize": input_size
            },
            "class_names": class_names,
            "feature_names": feature_names,
            "training_info": {
                "backbone": backbone,
                "learning_rate": learning_rate,
                "batch_size": batch_size,
                "epochs": completed_epochs,
                "best_epoch": best_epoch,
                "best_val_loss": best_val_loss,
                "best_val_accuracy": best_val_acc
            },
            "export_format": "PyTorch",
            "usage_examples": {
                "python": "# è¯·å‚è€ƒç¤ºä¾‹ä»£ç ä½¿ç”¨æ­¤æ¨¡å‹"
            }
        }
        
        # ä¿å­˜å…ƒæ•°æ®æ–‡ä»¶
        try:
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            return True, "å…ƒæ•°æ®åˆ›å»ºæˆåŠŸ"
        except Exception as e:
            return False, f"ä¿å­˜å…ƒæ•°æ®æ–‡ä»¶æ—¶å‡ºé”™: {e}"
            
    except Exception as e:
        traceback_info = traceback.format_exc()
        append_log(f"ç”Ÿæˆå…ƒæ•°æ®æ—¶å‡ºé”™: {traceback_info}")
        return False, f"ç”Ÿæˆå…ƒæ•°æ®æ—¶å‡ºé”™: {e}"

def batch_generate_metadata():
    """æ‰¹é‡ç”Ÿæˆç¼ºå¤±çš„å…ƒæ•°æ®"""
    results = []
    
    # åŠ è½½æ‰€æœ‰è®­ç»ƒè®°å½•
    all_results = load_results()
    
    for model_data in all_results:
        model_name = model_data.get("model_name", "")
        model_path = model_data.get("best_model_path", "")
        
        if not model_name or not model_path:
            results.append((model_name or "æœªå‘½åæ¨¡å‹", False, "æ¨¡å‹ä¿¡æ¯ä¸å®Œæ•´"))
            continue
            
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if model_path and not os.path.exists(model_path):
            results.append((model_name, False, f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}"))
            continue
        
        # æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        model_dir = os.path.dirname(model_path) if model_path else ""
        if not model_dir:
            results.append((model_name, False, "æ¨¡å‹è·¯å¾„ä¸å®Œæ•´"))
            continue
            
        metadata_file = os.path.join(model_dir, f"{model_name}_metadata.json")
        
        # å¦‚æœå…ƒæ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡
        if metadata_file and os.path.exists(metadata_file):
            results.append((model_name, True, "å…ƒæ•°æ®å·²å­˜åœ¨"))
            continue
        
        # ç”Ÿæˆå…ƒæ•°æ®
        try:
            success, message = generate_metadata_for_model(model_data)
            results.append((model_name, success, message))
        except Exception as e:
            results.append((model_name, False, f"ç”Ÿæˆå…ƒæ•°æ®æ—¶å‡ºé”™: {str(e)}"))
    
    return results

def create_metadata_file(model_name, model_data, metadata_input):
    """æ ¹æ®ç”¨æˆ·è¾“å…¥åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶"""
    try:
        if not model_name:
            return False, "æ¨¡å‹åç§°ä¸ºç©º"
            
        model_path = model_data.get("best_model_path", "")
        if not model_path:
            return False, "æ¨¡å‹è·¯å¾„ä¸ºç©º"
            
        if not os.path.exists(model_path):
            return False, f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}"
        
        # æå–æ¨¡å‹ç›®å½•
        model_dir = os.path.dirname(model_path)
        if not model_dir:
            return False, "æ— æ³•æå–æ¨¡å‹ç›®å½•"
            
        metadata_file = os.path.join(model_dir, f"{model_name}_metadata.json")
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if metadata_file and os.path.exists(metadata_file):
            # è¿›è¡Œè¦†ç›–ç¡®è®¤
            st.warning(f"å…ƒæ•°æ®æ–‡ä»¶ '{metadata_file}' å·²å­˜åœ¨ï¼Œå°†è¢«è¦†ç›–ã€‚")
        
        # å‡†å¤‡å…ƒæ•°æ®ç»“æ„
        metadata = {
            "model_name": model_name,
            "version": metadata_input.get("version", "1.0"),
            "description": metadata_input.get("description", "æœè£…åˆ†ç±»ä¸å±æ€§è¯†åˆ«æ¨¡å‹"),
            "date_created": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "architecture": f"ClothesModel({model_data.get('backbone', 'unknown')})",
            "input_shape": [3, model_data.get("image_size", 224), model_data.get("image_size", 224)],
            "preprocessing": {
                "mean": [0.485, 0.456, 0.406],
                "std": [0.229, 0.224, 0.225],
                "resize": model_data.get("image_size", 224)
            },
            # ä½¿ç”¨æä¾›çš„ç±»åˆ«å’Œç‰¹å¾åç§°
            "class_names": metadata_input.get("class_names", []),
            "feature_names": metadata_input.get("feature_names", []),
            "training_info": {
                "backbone": model_data.get("backbone", "unknown"),
                "learning_rate": model_data.get("learning_rate", 0.0001),
                "batch_size": model_data.get("batch_size", 32),
                "epochs": model_data.get("completed_epochs", 0),
                "best_epoch": model_data.get("best_epoch", 0),
                "best_val_loss": model_data.get("best_val_loss", 0.0),
                "best_val_accuracy": model_data.get("best_val_accuracy", 0.0),
                "status": model_data.get("status", "unknown")
            },
            "author": metadata_input.get("author", ""),
            "contact": metadata_input.get("contact", ""),
            "license": metadata_input.get("license", ""),
            "export_format": "PyTorch",
            "usage_notes": metadata_input.get("usage_notes", "")
        }
        
        # ä¿å­˜å…ƒæ•°æ®
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        return True, "å…ƒæ•°æ®åˆ›å»ºæˆåŠŸ"
    except Exception as e:
        traceback_info = traceback.format_exc()
        append_log(f"åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶æ—¶å‡ºé”™: {traceback_info}")
        return False, f"åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶æ—¶å‡ºé”™: {e}" 