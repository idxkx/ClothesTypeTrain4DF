import streamlit as st
import torch
import time
import pandas as pd
import math
import traceback
import os
import json
from datetime import datetime, timedelta
import re

from utils.state_manager import append_log
from utils.time_utils import format_time_delta, format_datetime
from utils.file_utils import save_results, load_results
from components.gpu_monitor import update_gpu_info

def _initialize_datasets(anno_dir, img_dir, transforms_config, ui_components):
    """åˆå§‹åŒ–è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†"""
    try:
        ui_components['status'].info("â³ æ­£åœ¨åŠ è½½æ•°æ®é›†...")
        append_log("åˆå§‹åŒ–è®­ç»ƒæ•°æ®é›†...")
        
        from dataset import DeepFashionDataset
        
        train_dataset = DeepFashionDataset(
            anno_dir_path=anno_dir,
            image_dir_path=img_dir,
            partition='train',
            transform=transforms_config['train']
        )
        append_log(f"è®­ç»ƒé›†åŠ è½½æˆåŠŸï¼Œæ ·æœ¬æ•°: {len(train_dataset)}")
        
        append_log("åˆå§‹åŒ–éªŒè¯æ•°æ®é›†...")
        val_dataset = DeepFashionDataset(
            anno_dir_path=anno_dir,
            image_dir_path=img_dir,
            partition='val',
            transform=transforms_config['val']
        )
        append_log(f"éªŒè¯é›†åŠ è½½æˆåŠŸï¼Œæ ·æœ¬æ•°: {len(val_dataset)}")
        
        ui_components['status'].success("âœ… æ•°æ®é›†åŠ è½½å®Œæˆ!")
        return train_dataset, val_dataset
        
    except FileNotFoundError as e:
        error_msg = f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°å¿…è¦çš„æ•°æ®æ–‡ä»¶æˆ–ç›®å½•ï¼è¯·æ£€æŸ¥ä½ è¾“å…¥çš„ Anno_fine ç›®å½• '{anno_dir}' å’Œå›¾ç‰‡ç›®å½• '{img_dir}' æ˜¯å¦æ­£ç¡®ä¸”å­˜åœ¨ã€‚è¯¦ç»†é”™è¯¯: {e}"
        st.error(error_msg)
        append_log(error_msg)
        ui_components['status'].error("âŒ æ•°æ®é›†åŠ è½½å¤±è´¥ï¼")
        return None, None
        
    except ValueError as e:
        error_msg = f"é”™è¯¯ï¼šåŠ è½½æˆ–è§£æåˆ†åŒºæ–‡ä»¶æ—¶å‡ºé”™ã€‚è¯·æ£€æŸ¥ '{anno_dir}' ç›®å½•ä¸‹çš„åˆ†åŒºæ–‡ä»¶ (å¦‚ train.txt, train_cate.txt) æ˜¯å¦å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®ã€‚è¯¦ç»†é”™è¯¯: {e}"
        st.error(error_msg)
        append_log(error_msg)
        ui_components['status'].error("âŒ æ•°æ®é›†åŠ è½½å¤±è´¥ï¼")
        return None, None
        
    except Exception as e:
        error_msg = f"é”™è¯¯ï¼šåŠ è½½æ•°æ®é›†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"
        st.error(error_msg)
        append_log(error_msg)
        ui_components['status'].error("âŒ æ•°æ®é›†åŠ è½½å¤±è´¥ï¼")
        traceback.print_exc()
        return None, None

def _initialize_model(backbone, device, ui_components):
    """åˆå§‹åŒ–æ¨¡å‹"""
    try:
        ui_components['status'].info("â³ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
        append_log(f"åˆå§‹åŒ–æ¨¡å‹ (Backbone: {backbone})...")
        
        from model import ClothesModel
        
        num_categories = 50  # å¯èƒ½éœ€è¦ä¿®æ”¹ä¸ºåŠ¨æ€è·å–
        model = ClothesModel(
            num_categories=num_categories,
            backbone=backbone
        )
        
        append_log(f"æ¨¡å‹åˆå§‹åŒ–æˆåŠŸã€‚å°†æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡: {device}")
        model.to(device)
        
        ui_components['status'].success("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ!")
        return model
        
    except Exception as e:
        error_msg = f"é”™è¯¯ï¼šåˆå§‹åŒ–æ¨¡å‹ '{backbone}' æ—¶å‘ç”Ÿé”™è¯¯: {e}"
        st.error(error_msg)
        append_log(error_msg)
        ui_components['status'].error("âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼è¯·æ£€æŸ¥é€‰æ‹©çš„éª¨å¹²ç½‘ç»œæ˜¯å¦å¯ç”¨æˆ–å·²å®‰è£… `timm` åº“ã€‚")
        traceback.print_exc()
        return None

def _initialize_trainer(model, train_dataset, val_dataset, args, ui_components):
    """åˆå§‹åŒ–è®­ç»ƒå™¨"""
    try:
        ui_components['status'].info("â³ æ­£åœ¨åˆå§‹åŒ–è®­ç»ƒå™¨...")
        append_log("åˆå§‹åŒ– Trainer...")
        
        from trainer import Trainer
        
        trainer = Trainer(model, train_dataset, val_dataset, args)
        append_log("Trainer åˆå§‹åŒ–æˆåŠŸ.")
        
        ui_components['status'].success("âœ… è®­ç»ƒå™¨å‡†å¤‡å°±ç»ª!")
        return trainer
        
    except Exception as e:
        error_msg = f"é”™è¯¯ï¼šåˆå§‹åŒ– Trainer æ—¶å‘ç”Ÿé”™è¯¯: {e}"
        st.error(error_msg)
        append_log(error_msg)
        ui_components['status'].error("âŒ Trainer åˆå§‹åŒ–å¤±è´¥ï¼")
        traceback.print_exc()
        return None

def _initialize_run_result(training_params, device):
    """åˆå§‹åŒ–è®­ç»ƒç»“æœè®°å½•"""
    return {
        "start_time": st.session_state.training_start_time,
        "start_time_str": datetime.fromtimestamp(st.session_state.training_start_time).strftime('%Y-%m-%d %H:%M:%S'),
        "date_created": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        "model_name": training_params['model_name'],
        "strategy": training_params['strategy_choice'],
        "parameters": {k: v for k, v in training_params.items() if k != 'strategy_choice'},
        "backbone": training_params['backbone'],
        "anno_dir": training_params['anno_dir'],
        "img_dir": training_params['img_dir'],
        "status": "ongoing",
        "total_epochs": training_params['epochs'],
        "completed_epochs": 0,
        "best_val_loss": float('inf'),
        "best_epoch": None,
        "best_model_path": None,
        "diagnostic_summary": None,
        "functional_test_result": "æœªæ‰§è¡Œ",
        "end_time": None,
        "end_time_str": None,
        "duration": None,
        "duration_str": None,
    }

def _execute_training(trainer, device, gpu_index, ui_components, current_run_result, results_file):
    """æ‰§è¡Œè®­ç»ƒå¾ªç¯"""
    append_log("\n==================== å¼€å§‹è®­ç»ƒ ====================")
    ui_components['status'].info(f"ğŸš€ æ¨¡å‹è®­ç»ƒä¸­... è®¾å¤‡: {device}")
    
    best_val_loss = float('inf')
    best_model_file_path = None
    training_interrupted = False
    history_df = None
    
    try:
        for epoch in range(trainer.epochs):
            epoch_start_time = time.time()
            
            # æ£€æŸ¥æ˜¯å¦è¯·æ±‚åœæ­¢
            if st.session_state.get('stop_requested', False):
                append_log("è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­ã€‚")
                ui_components['status'].warning("âš ï¸ è®­ç»ƒå·²åœæ­¢ã€‚")
                training_interrupted = True
                # æ–°å¢ï¼šä¸­æ–­æ—¶å†™å…¥çŠ¶æ€å’Œæ—¶é—´
                current_run_result["status"] = "failed"
                if not current_run_result.get("date_created"):
                    current_run_result["date_created"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                all_results = load_results(results_file)
                all_results = [r for r in all_results if r.get('model_name') != current_run_result['model_name']]
                all_results.append(current_run_result)
                save_results(all_results, results_file)
                append_log(f"è®­ç»ƒè¢«ä¸­æ–­ï¼Œå·²ä¿å­˜è®°å½•åˆ° {results_file}")
                break
            
            ui_components['status'].info(f"Epoch {epoch+1}/{trainer.epochs}: æ­£åœ¨è®­ç»ƒ...")
            append_log(f"\n--- å¼€å§‹è®­ç»ƒ Epoch {epoch+1}/{trainer.epochs} ---")
            
            # æ›´æ–°GPUä¿¡æ¯
            if gpu_index is not None:
                update_gpu_info(gpu_index, ui_components['gpu_info'], ui_components['gpu_charts'])
            
            # è®­ç»ƒé˜¶æ®µ
            train_metrics = _train_epoch(trainer, epoch, ui_components)
            
            # å¦‚æœè®­ç»ƒè¢«ä¸­æ–­ï¼Œåˆ™è·³å‡ºå¾ªç¯
            if st.session_state.get('stop_requested', False):
                append_log("è®­ç»ƒåœ¨æ‰¹æ¬¡å¤„ç†ä¸­è¢«ä¸­æ–­...")
                training_interrupted = True
                # æ–°å¢ï¼šä¸­æ–­æ—¶å†™å…¥çŠ¶æ€å’Œæ—¶é—´
                current_run_result["status"] = "failed"
                if not current_run_result.get("date_created"):
                    current_run_result["date_created"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                all_results = load_results(results_file)
                all_results = [r for r in all_results if r.get('model_name') != current_run_result['model_name']]
                all_results.append(current_run_result)
                save_results(all_results, results_file)
                append_log(f"è®­ç»ƒè¢«ä¸­æ–­ï¼Œå·²ä¿å­˜è®°å½•åˆ° {results_file}")
                break
            
            # éªŒè¯é˜¶æ®µ
            val_metrics = _validate_epoch(trainer, ui_components)
            
            # è®¡ç®—æœ¬è½®è€—æ—¶
            epoch_end_time = time.time()
            epoch_time = epoch_end_time - epoch_start_time
            
            # æ›´æ–°ç•Œé¢
            from components.training_panel import update_training_ui
            update_training_ui(
                epoch, trainer.epochs, 
                train_metrics, val_metrics, 
                epoch_time, ui_components
            )
            
            # æ›´æ–°GPUä¿¡æ¯
            if gpu_index is not None:
                update_gpu_info(gpu_index, ui_components['gpu_info'], ui_components['gpu_charts'])
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if math.isfinite(val_metrics['loss']) and val_metrics['loss'] < best_val_loss:
                best_val_loss = val_metrics['loss']
                if trainer.model_save_path:
                    # åˆ é™¤æ—§çš„æœ€ä½³æ¨¡å‹
                    _clean_old_model_files(trainer.model_save_path, current_run_result['model_name'])
                    
                    # ä¿å­˜æ–°çš„æœ€ä½³æ¨¡å‹
                    best_model_file_path = _save_best_model(
                        trainer, current_run_result['model_name'], epoch, val_metrics['loss']
                    )
                    
                    # æ›´æ–°å½“å‰è¿è¡Œè®°å½•
                    current_run_result["best_val_loss"] = val_metrics['loss']
                    current_run_result["best_epoch"] = epoch + 1
                    current_run_result["best_model_path"] = best_model_file_path
            
            # æ›´æ–°å®Œæˆè½®æ•°
            current_run_result["completed_epochs"] = epoch + 1
            
            # æ¯è½®ç»“æŸåä¿å­˜è®­ç»ƒè®°å½•
            all_results = load_results(results_file)
            # ç§»é™¤ä¹‹å‰çš„ç›¸åŒæ¨¡å‹è®°å½•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            all_results = [r for r in all_results if r.get('model_name') != current_run_result['model_name']]
            # æ·»åŠ å½“å‰è®°å½•
            all_results.append(current_run_result)
            save_results(all_results, results_file)
            append_log(f"å·²ä¿å­˜å½“å‰è®­ç»ƒè¿›åº¦åˆ° {results_file}")
        
        # è®­ç»ƒå®Œæˆï¼Œè®¾ç½®çŠ¶æ€
        training_success = not training_interrupted
        
        if training_success:
            current_run_result["status"] = "completed"
            append_log("è®­ç»ƒæˆåŠŸå®Œæˆï¼")
        else:
            current_run_result["status"] = "failed"
            append_log("è®­ç»ƒè¢«ä¸­æ–­ï¼")
        
        # æ„å»ºå†å²DataFrame
        history_df = pd.DataFrame(st.session_state.history_df_list).dropna(subset=['epoch'])
        
        return training_success, best_val_loss, history_df
        
    except Exception as e:
        error_msg = f"é”™è¯¯ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"
        st.error(error_msg)
        append_log(error_msg)
        ui_components['status'].error("âŒ è®­ç»ƒå¤±è´¥ï¼")
        traceback.print_exc()
        current_run_result["status"] = "failed"
        if not current_run_result.get("date_created"):
            current_run_result["date_created"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        # å³ä½¿å‘ç”Ÿé”™è¯¯ä¹Ÿä¿å­˜è®­ç»ƒè®°å½•
        all_results = load_results(results_file)
        all_results = [r for r in all_results if r.get('model_name') != current_run_result['model_name']]
        all_results.append(current_run_result)
        save_results(all_results, results_file)
        append_log(f"å·²ä¿å­˜è®­ç»ƒé”™è¯¯è®°å½•åˆ° {results_file}")
        return False, float('inf'), None

def _train_epoch(trainer, epoch, ui_components):
    """æ‰§è¡Œå•è½®è®­ç»ƒ"""
    trainer.model.train()
    train_loss, train_correct_cats, train_total_samples = 0.0, 0, 0
    num_batches = len(trainer.train_loader)
    
    for i, batch in enumerate(trainer.train_loader):
        # æ¯10ä¸ªæ‰¹æ¬¡æ£€æŸ¥æ˜¯å¦è¯·æ±‚åœæ­¢
        if i % 10 == 0 and st.session_state.get('stop_requested', False):
            return {
                'loss': float('inf'),
                'accuracy': 0.0
            }
        
        try:
            images = batch['image'].to(trainer.device, non_blocking=True)
            cat_labels = batch['category'].to(trainer.device, non_blocking=True)
            attr_labels = batch['attributes'].to(trainer.device, non_blocking=True)
            
            trainer.optimizer.zero_grad()
            cat_logits, attr_logits = trainer.model(images)
            
            valid_cat_mask = cat_labels != -1
            if valid_cat_mask.sum() == 0:
                loss_cat = torch.tensor(0.0).to(trainer.device)
            else:
                loss_cat = trainer.criterion_category(cat_logits[valid_cat_mask], cat_labels[valid_cat_mask])
                
            loss_attr = trainer.criterion_attribute(attr_logits, attr_labels)
            
            if not (torch.isfinite(loss_cat) and torch.isfinite(loss_attr)):
                append_log(f"è­¦å‘Š: Epoch {epoch+1}, Batch {i+1}, æ— æ•ˆæŸå¤± (Cat: {loss_cat.item():.4f}, Attr: {loss_attr.item():.4f})ï¼Œè·³è¿‡.")
                continue
                
            loss = loss_cat + trainer.attribute_loss_weight * loss_attr
            loss.backward()
            trainer.optimizer.step()
            
            batch_size_actual = images.size(0)
            train_loss += loss.item() * batch_size_actual
            
            if valid_cat_mask.sum() > 0:
                _, predicted_cats = torch.max(cat_logits.data, 1)
                train_correct_cats += (predicted_cats[valid_cat_mask] == cat_labels[valid_cat_mask]).sum().item()
                train_total_samples += valid_cat_mask.sum().item()
            
            # æ¯50ä¸ªæ‰¹æ¬¡æ›´æ–°çŠ¶æ€
            if (i + 1) % 50 == 0 or (i + 1) == num_batches:
                current_avg_loss = train_loss / ((i + 1) * batch_size_actual) if batch_size_actual > 0 else 0
                ui_components['status'].info(f"Epoch {epoch+1}/{trainer.epochs}: è®­ç»ƒä¸­... Batch {i+1}/{num_batches} ({(i + 1)*100/num_batches:.0f}%) | Batch Loss: {loss.item():.4f}")
                
        except Exception as batch_e:
            append_log(f"é”™è¯¯: Epoch {epoch+1}, Batch {i+1} å¤„ç†å¤±è´¥: {batch_e}")
            traceback.print_exc()
            continue
    
    # è®¡ç®—å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
    avg_train_loss = train_loss / train_total_samples if train_total_samples > 0 else float('inf')
    avg_train_cat_acc = 100.0 * train_correct_cats / train_total_samples if train_total_samples > 0 else 0.0
    
    append_log(f"--- Epoch {epoch+1} è®­ç»ƒå®Œæˆ (Avg Loss: {avg_train_loss:.4f}, Cat Acc: {avg_train_cat_acc:.2f}%) ---")
    
    return {
        'loss': avg_train_loss,
        'accuracy': avg_train_cat_acc
    }

def _validate_epoch(trainer, ui_components):
    """æ‰§è¡Œå•è½®éªŒè¯"""
    if not trainer.val_loader or len(trainer.val_loader.dataset) == 0:
        append_log(f"--- æ— éªŒè¯é›†æˆ–éªŒè¯é›†ä¸ºç©ºï¼Œè·³è¿‡éªŒè¯ ---")
        return {
            'loss': float('nan'),
            'accuracy': float('nan')
        }
    
    trainer.model.eval()
    val_loss, val_correct_cats, val_total_samples = 0.0, 0, 0
    
    with torch.no_grad():
        for i, batch in enumerate(trainer.val_loader):
            try:
                images = batch['image'].to(trainer.device, non_blocking=True)
                cat_labels = batch['category'].to(trainer.device, non_blocking=True)
                attr_labels = batch['attributes'].to(trainer.device, non_blocking=True)
                
                cat_logits, attr_logits = trainer.model(images)
                
                loss_cat = trainer.criterion_category(cat_logits, cat_labels)
                loss_attr = trainer.criterion_attribute(attr_logits, attr_labels)
                
                if not (torch.isfinite(loss_cat) and torch.isfinite(loss_attr)):
                    append_log(f"è­¦å‘Š: éªŒè¯ Batch {i+1}, æ— æ•ˆæŸå¤±ï¼Œè·³è¿‡.")
                    continue
                    
                loss = loss_cat + trainer.attribute_loss_weight * loss_attr
                
                batch_size = images.size(0)
                val_loss += loss.item() * batch_size
                
                _, predicted_cats = torch.max(cat_logits.data, 1)
                val_correct_cats += (predicted_cats == cat_labels).sum().item()
                val_total_samples += batch_size
                
            except Exception as batch_e:
                append_log(f"é”™è¯¯: éªŒè¯ Batch {i+1} å¤„ç†å¤±è´¥: {batch_e}")
                continue
    
    # è®¡ç®—å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
    avg_val_loss = val_loss / val_total_samples if val_total_samples > 0 else float('inf')
    avg_val_cat_acc = 100.0 * val_correct_cats / val_total_samples if val_total_samples > 0 else 0.0
    
    append_log(f"--- éªŒè¯å®Œæˆ (Avg Loss: {avg_val_loss:.4f}, Cat Acc: {avg_val_cat_acc:.2f}%) ---")
    
    return {
        'loss': avg_val_loss,
        'accuracy': avg_val_cat_acc
    }

def _clean_old_model_files(model_save_path, model_name):
    """æ¸…ç†æ—§çš„æœ€ä½³æ¨¡å‹æ–‡ä»¶"""
    # æå–æ¨¡å‹åç§°çš„åŸºç¡€éƒ¨åˆ†ï¼Œä»¥ä¾¿æ›´çµæ´»åœ°åŒ¹é…æ–‡ä»¶
    # å¦‚æœæœ‰æ—¶é—´æˆ³æ ¼å¼ (_MMDD_HHMM)ï¼Œå»é™¤å®ƒç”¨äºåŒ¹é…
    base_model_name = re.sub(r'_\d{4}_\d{4}$', '', model_name)
    
    # åˆ›å»ºæ›´å¼ºå¤§çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼è¿›è¡ŒåŒ¹é…
    # è¿™å…è®¸åŒ¹é…å®Œæ•´æ¨¡å‹åæˆ–ä¸å¸¦æ—¶é—´æˆ³çš„åŸºç¡€åç§°
    pattern = rf"best_model_(({re.escape(model_name)})|({re.escape(base_model_name)}))(_\d+)?_epoch\d+\.pth"
    
    deleted_count = 0
    for old_file in os.listdir(model_save_path):
        if re.match(pattern, old_file):
            try:
                os.remove(os.path.join(model_save_path, old_file))
                append_log(f"å·²åˆ é™¤æ—§çš„æœ€ä½³æ¨¡å‹: {old_file}")
                deleted_count += 1
            except OSError as e:
                append_log(f"æ— æ³•åˆ é™¤æ—§æ¨¡å‹ {old_file}: {e}")
    
    append_log(f"æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {deleted_count} ä¸ªæ—§æ¨¡å‹æ–‡ä»¶")

def _save_best_model(trainer, model_name, epoch, val_loss):
    """ä¿å­˜æœ€ä½³æ¨¡å‹"""
    # é¦–å…ˆæ£€æŸ¥ä¿å­˜è·¯å¾„æ˜¯å¦æœ‰æ•ˆ
    if not trainer.model_save_path:
        append_log("é”™è¯¯ï¼šæ¨¡å‹ä¿å­˜è·¯å¾„æ— æ•ˆï¼Œæ— æ³•ä¿å­˜æ¨¡å‹")
        return None
        
    # ä¸ºé¿å…æ¨¡å‹åç§°é‡å¤ï¼Œæ·»åŠ å½“å‰æ—¶é—´ï¼ˆMMDD_HHMMæ ¼å¼ï¼‰
    now = datetime.now()
    time_suffix = ""
    
    # æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦å·²åŒ…å«æ—¶é—´æˆ³ï¼Œå¦‚æœæ²¡æœ‰ï¼Œæ·»åŠ æ—¶é—´æˆ³
    if not re.search(r'_\d{4}_\d{4}$', model_name):
        time_suffix = f"_{now.strftime('%m%d_%H%M')}"
    
    # æ„å»ºå®Œæ•´çš„æ–‡ä»¶åï¼ŒåŒ…æ‹¬æ¨¡å‹åå’Œæ—¶é—´æˆ³(å¦‚æœéœ€è¦)
    filename = f"best_model_{model_name}{time_suffix}_epoch{epoch+1}.pth"
    save_filename = os.path.join(trainer.model_save_path, filename)
    
    try:
        torch.save(trainer.model.state_dict(), save_filename)
        append_log(f"** æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°: {save_filename} (Val Loss: {val_loss:.4f}) **")
        
        # ç¡®è®¤æ–‡ä»¶æ˜¯å¦å·²æˆåŠŸåˆ›å»º
        if os.path.exists(save_filename):
            return save_filename
        else:
            append_log("è­¦å‘Šï¼šæ¨¡å‹æ–‡ä»¶ä¼¼ä¹æœªæˆåŠŸåˆ›å»ºï¼Œè·¯å¾„å¯èƒ½æ— æ•ˆ")
            return None
    except Exception as e:
        append_log(f"é”™è¯¯ï¼šä¿å­˜æ¨¡å‹æ—¶å‡ºé”™: {e}")
        return None

def _finalize_training(training_success, history_df, best_val_loss, model_save_dir, 
                      training_params, current_run_result, ui_components, device, results_file):
    """å®Œæˆè®­ç»ƒåçš„æ”¶å°¾å·¥ä½œ"""
    # è®¡ç®—æ€»è®­ç»ƒæ—¶é—´
    end_time = time.time()
    total_time = end_time - current_run_result["start_time"]
    
    # æ›´æ–°ç»“æœè®°å½•
    current_run_result["end_time"] = end_time
    current_run_result["end_time_str"] = datetime.fromtimestamp(end_time).strftime('%Y-%m-%d %H:%M:%S')
    current_run_result["duration"] = total_time
    current_run_result["duration_str"] = format_time_delta(total_time)
    
    # è®°å½•æœ€ç»ˆæ—¥å¿—
    append_log(f"æ€»è®­ç»ƒæ—¶é—´: {total_time:.2f} ç§’")
    formatted_best_loss = f"{best_val_loss:.4f}" if math.isfinite(best_val_loss) else "N/A"
    append_log(f"æœ€ä½³éªŒè¯æŸå¤±: {formatted_best_loss}")
    
    # ä¿å­˜è®­ç»ƒæ•°æ®
    current_run_result = _save_training_data(current_run_result)
    
    # æ˜¾ç¤ºæœ€ç»ˆæ—¶é—´ä¿¡æ¯
    _show_final_time_info(total_time, ui_components['time_info'])
    
    # ç¡®ä¿æœ€åä¸€æ¬¡æ›´æ–°æ—¥å¿—
    ui_components['log'].code("\n".join(st.session_state.log_messages), language='log')
    
    # ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
    if history_df is not None and not history_df.empty:
        from components.report_generator import generate_diagnostic_report
        diagnostic_report, evaluation_data = generate_diagnostic_report(history_df, best_val_loss, training_params['epochs'])
        ui_components['diagnostic'].markdown(diagnostic_report)
        append_log("\n--- è¯Šæ–­æŠ¥å‘Šå·²ç”Ÿæˆ ---")
        
        # ä¿å­˜è¯Šæ–­æŠ¥å‘Šæ–‡æœ¬å’Œç»“æ„åŒ–è¯„ä¼°æ•°æ®
        current_run_result["diagnostic_summary"] = diagnostic_report
        current_run_result["evaluation"] = evaluation_data  # æ·»åŠ ç»“æ„åŒ–è¯„ä¼°æ•°æ®
    else:
        current_run_result["diagnostic_summary"] = "æ— è®­ç»ƒå†å²æ•°æ®"
        current_run_result["evaluation"] = {
            "overfitting_risk": "æœªçŸ¥",
            "loss_diff": float('nan'),
            "accuracy_diff": float('nan'),
            "convergence_status": "æœªçŸ¥"
        }
    
    # ç¡®ä¿è®­ç»ƒçŠ¶æ€ä¸ºæˆåŠŸï¼Œæ— è®ºåŠŸèƒ½æµ‹è¯•æ˜¯å¦é€šè¿‡
    if training_success:
        current_run_result["status"] = "completed"
        append_log("è®­ç»ƒæˆåŠŸå®Œæˆï¼")
    else:
        current_run_result["status"] = "failed"
        append_log("è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ã€‚")
    
    # æ‰§è¡ŒåŠŸèƒ½æµ‹è¯•ï¼Œä½†ä¸å½±å“è®­ç»ƒæˆåŠŸçŠ¶æ€
    test_success = False
    if current_run_result.get("best_model_path") and os.path.exists(current_run_result["best_model_path"]):
        # å…ˆç¡®è®¤å…ƒæ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        model_name = training_params['model_name']
        metadata_file = os.path.join(model_save_dir, f"{model_name}_metadata.json")
        
        if not os.path.exists(metadata_file):
            ui_components['functional_test'].error(f"å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metadata_file}")
            append_log(f"å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metadata_file}ï¼ŒåŠŸèƒ½æµ‹è¯•å°†å¤±è´¥")
            ui_components['functional_test'].warning("è¯·æ‰‹åŠ¨åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶åå†è¿›è¡ŒåŠŸèƒ½æµ‹è¯•ï¼Œæˆ–ä½¿ç”¨fix_metadata.pyå·¥å…·")
            
            # è®¾ç½®åŠŸèƒ½æµ‹è¯•ç»“æœä¸ºå¤±è´¥ï¼Œå¹¶æä¾›è¯¦ç»†åŸå› 
            current_run_result["functional_test_result"] = "failed"
            current_run_result["functional_test_error"] = {
                "error_type": "missing_metadata",
                "message": f"å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metadata_file}",
                "solution": "è¯·æ‰‹åŠ¨åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶æˆ–ä½¿ç”¨fix_metadata.pyå·¥å…·"
            }
            return
        
        # æ‰§è¡ŒåŠŸèƒ½æµ‹è¯•
        from components.report_generator import run_functional_test
        model_config = {
            'num_categories': 50,  # å‡è®¾ç±»åˆ«æ•°ä¸º50
            'backbone': training_params['backbone']
        }
        test_report, test_success, error_details = run_functional_test(
            model_save_dir, training_params['model_name'], model_config, device
        )
        ui_components['functional_test'].markdown(test_report)
        
        if not test_success and error_details:
            # æ·»åŠ é”™è¯¯è¯¦æƒ…åˆ°æµ‹è¯•æŠ¥å‘Šä¸­
            error_solution = error_details.get("solution", "è¯·å°è¯•é‡æ–°è®­ç»ƒæ¨¡å‹æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚")
            error_message = error_details.get("message", "æœªçŸ¥é”™è¯¯")
            error_type = error_details.get("error_type", "unknown")
            
            # æ„å»ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
            error_info = f"""
            ### âŒ åŠŸèƒ½æµ‹è¯•å¤±è´¥è¯¦æƒ…
            - **é”™è¯¯ç±»å‹**: {error_type}
            - **é”™è¯¯ä¿¡æ¯**: {error_message}
            - **å»ºè®®è§£å†³æ–¹æ¡ˆ**: {error_solution}
            """
            ui_components['functional_test'].error(error_info)
            
        log_summary = "åŠŸèƒ½æµ‹è¯•æˆåŠŸ" if test_success else f"åŠŸèƒ½æµ‹è¯•å¤±è´¥: {error_details.get('error_type', 'æœªçŸ¥é”™è¯¯')}"
        append_log(f"\n--- åŠŸèƒ½æ¨¡æ‹Ÿæµ‹è¯• --- \n{log_summary}")
        current_run_result["functional_test_result"] = "success" if test_success else "failed"
        # æ·»åŠ é”™è¯¯è¯¦æƒ…åˆ°è®­ç»ƒç»“æœ
        if not test_success:
            current_run_result["functional_test_error"] = error_details
    else:
        if not current_run_result.get("best_model_path"):
            ui_components['functional_test'].warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æœ€ä½³æ¨¡å‹è·¯å¾„ï¼Œè·³è¿‡åŠŸèƒ½æµ‹è¯•ã€‚")
            append_log("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æœ€ä½³æ¨¡å‹è·¯å¾„ï¼Œè·³è¿‡åŠŸèƒ½æµ‹è¯•ã€‚")
            current_run_result["functional_test_result"] = "skipped (no model path)"
        elif not os.path.exists(current_run_result["best_model_path"]):
            ui_components['functional_test'].warning("æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡åŠŸèƒ½æµ‹è¯•ã€‚")
            append_log(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {current_run_result['best_model_path']}ï¼Œè·³è¿‡åŠŸèƒ½æµ‹è¯•ã€‚")
            current_run_result["functional_test_result"] = "skipped (model file not found)"
    
    # ä¿å­˜å½“å‰è¿è¡Œç»“æœ
    all_results = load_results(results_file)
    all_results.append(current_run_result)
    save_results(all_results, results_file)
    append_log(f"å½“å‰è®­ç»ƒç»“æœå·²è¿½åŠ åˆ° {results_file}")
    
    from components.history_viewer import display_history
    display_history()
    
    # æ¸…ç†GPUç›‘æ§
    from components.gpu_monitor import shutdown_gpu
    shutdown_gpu()

def _save_training_data(current_run_result):
    """ä¿å­˜è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ•°æ®"""
    # ä¿å­˜è®­ç»ƒå†å²
    if 'history_df_list' in st.session_state:
        current_run_result['training_history'] = st.session_state.history_df_list
    
    # ä¿å­˜GPUç›‘æ§æ•°æ®
    if 'gpu_metrics_history' in st.session_state:
        current_run_result['gpu_metrics_history'] = st.session_state.gpu_metrics_history
    
    # ä¿å­˜è®­ç»ƒæ—¥å¿—
    if 'log_messages' in st.session_state:
        current_run_result['log_messages'] = st.session_state.log_messages
    
    return current_run_result

def _show_final_time_info(total_time, time_info_placeholder):
    """æ˜¾ç¤ºæœ€ç»ˆæ—¶é—´ç»Ÿè®¡ä¿¡æ¯"""
    if len(st.session_state.epoch_durations) > 0:
        final_avg_epoch_time = sum(st.session_state.epoch_durations) / len(st.session_state.epoch_durations)
        final_time_info_str = (
            f"â±ï¸ **æœ€ç»ˆç»Ÿè®¡:**  "
            f"æ€»è€—æ—¶: {format_time_delta(total_time)} | "
            f"å¹³å‡æ¯è½®: {final_avg_epoch_time:.2f} ç§’ (å…± {len(st.session_state.epoch_durations)} è½®)"
        )
        time_info_placeholder.markdown(final_time_info_str) 